Initializing cgroup subsys cpuset
Initializing cgroup subsys cpu
Linux version 2.6.32-431.11.2.res6.x86_64 (XXX@XXX) (gcc version 4.4.7 20120313 (ROSA 4.4.7-4) (GCC) ) #1 SMP Wed Mar 26 06:23:31 EDT 2014
Command line: ro root=/dev/mapper/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX rd_NO_LUKS LANG=ru_RU.UTF-8 rd_NO_MD quiet SYSFONT=latarcyrheb-sun16 rhgb crashkernel=auto rd_LVM_LV=vg_rosabuildclients004/lv_swap  KEYBOARDTYPE=pc KEYTABLE=us rd_LVM_LV=vg_rosabuildclients004/lv_root rd_NO_DM
KERNEL supported cpus:
  Intel GenuineIntel
  AMD AuthenticAMD
  Centaur CentaurHauls
BIOS-provided physical RAM map:
 BIOS-e820: 0000000000000000 - 0000000000098800 (usable)
 BIOS-e820: 0000000000098800 - 00000000000a0000 (reserved)
 BIOS-e820: 00000000000e4000 - 0000000000100000 (reserved)
 BIOS-e820: 0000000000100000 - 00000000bf780000 (usable)
 BIOS-e820: 00000000bf78e000 - 00000000bf790000 type 9
 BIOS-e820: 00000000bf790000 - 00000000bf79e000 (ACPI data)
 BIOS-e820: 00000000bf79e000 - 00000000bf7d0000 (ACPI NVS)
 BIOS-e820: 00000000bf7d0000 - 00000000bf7e0000 (reserved)
 BIOS-e820: 00000000bf7ec000 - 00000000c0000000 (reserved)
 BIOS-e820: 00000000e0000000 - 00000000f0000000 (reserved)
 BIOS-e820: 00000000fee00000 - 00000000fee01000 (reserved)
 BIOS-e820: 00000000ffc00000 - 0000000100000000 (reserved)
 BIOS-e820: 0000000100000000 - 0000001840000000 (usable)
DMI present.
SMBIOS version 2.6 @ 0xFBAD0
DMI: Supermicro X8DTL/X8DTL, BIOS 2.0c       01/05/11  
AMI BIOS detected: BIOS may corrupt low RAM, working around it.
e820 update range: 0000000000000000 - 0000000000010000 (usable) ==> (reserved)
e820 update range: 0000000000000000 - 0000000000001000 (usable) ==> (reserved)
e820 remove range: 00000000000a0000 - 0000000000100000 (usable)
last_pfn = 0x1840000 max_arch_pfn = 0x400000000
MTRR default type: uncachable
MTRR fixed ranges enabled:
  00000-9FFFF write-back
  A0000-DFFFF uncachable
  E0000-E7FFF write-through
  E8000-FFFFF write-protect
MTRR variable ranges enabled:
  0 base 0000000000 mask F000000000 write-back
  1 base 1000000000 mask F800000000 write-back
  2 base 1800000000 mask FFC0000000 write-back
  3 base 00C0000000 mask FFC0000000 uncachable
  4 base 00BF800000 mask FFFF800000 uncachable
  5 disabled
  6 disabled
  7 disabled
  8 disabled
  9 disabled
x86 PAT enabled: cpu 0, old 0x7040600070406, new 0x7010600070106
original variable MTRRs
reg 0, base: 0GB, range: 64GB, type WB
reg 1, base: 64GB, range: 32GB, type WB
reg 2, base: 96GB, range: 1GB, type WB
reg 3, base: 3GB, range: 1GB, type UC
reg 4, base: 3064MB, range: 8MB, type UC
total RAM covered: 98296M
Found optimal setting for mtrr clean up
 gran_size: 64K 	chunk_size: 16M 	num_reg: 9  	lose cover RAM: 0G
New variable MTRRs
reg 0, base: 0GB, range: 2GB, type WB
reg 1, base: 2GB, range: 1GB, type WB
reg 2, base: 3064MB, range: 8MB, type UC
reg 3, base: 4GB, range: 4GB, type WB
reg 4, base: 8GB, range: 8GB, type WB
reg 5, base: 16GB, range: 16GB, type WB
reg 6, base: 32GB, range: 32GB, type WB
reg 7, base: 64GB, range: 32GB, type WB
reg 8, base: 96GB, range: 1GB, type WB
e820 update range: 00000000bf800000 - 0000000100000000 (usable) ==> (reserved)
last_pfn = 0xbf780 max_arch_pfn = 0x400000000
initial memory mapped : 0 - 20000000
Using GB pages for direct mapping
init_memory_mapping: 0000000000000000-00000000bf780000
 0000000000 - 0080000000 page 1G
 0080000000 - 00bf600000 page 2M
 00bf600000 - 00bf780000 page 4k
kernel direct mapping tables up to bf780000 @ 10000-13000
Use unified mapping for non-reserved e820 regions.
init_memory_mapping: 0000000100000000-0000001840000000
 0100000000 - 1840000000 page 1G
kernel direct mapping tables up to 1840000000 @ 12000-13000
RAMDISK: 37045000 - 37fef0c0
ACPI: RSDP 00000000000fabe0 00024 (v02 ACPIAM)
ACPI: XSDT 00000000bf790100 00084 (v01 SMCI            20110105 MSFT 00000097)
ACPI: FACP 00000000bf790290 000F4 (v03 010511 FACP1122 20110105 MSFT 00000097)
ACPI: DSDT 00000000bf7906a0 0655C (v01  10006 10006000 00000000 INTL 20051117)
ACPI: FACS 00000000bf79e000 00040
ACPI: APIC 00000000bf790390 0011E (v01 010511 APIC1122 20110105 MSFT 00000097)
ACPI: MCFG 00000000bf7904b0 0003C (v01 010511 OEMMCFG  20110105 MSFT 00000097)
ACPI: SLIT 00000000bf7904f0 00030 (v01 010511 OEMSLIT  20110105 MSFT 00000097)
ACPI: OEMB 00000000bf79e040 00085 (v01 010511 OEMB1122 20110105 MSFT 00000097)
ACPI: SRAT 00000000bf79a6a0 00250 (v01 010511 OEMSRAT  00000001 INTL 00000001)
ACPI: HPET 00000000bf79a8f0 00038 (v01 010511 OEMHPET  20110105 MSFT 00000097)
ACPI: SSDT 00000000bf7a3ed0 00363 (v01 DpgPmm    CpuPm 00000012 INTL 20051117)
ACPI: EINJ 00000000bf79a930 00130 (v01  AMIER AMI_EINJ 20110105 MSFT 00000097)
ACPI: BERT 00000000bf79aac0 00030 (v01  AMIER AMI_BERT 20110105 MSFT 00000097)
ACPI: ERST 00000000bf79aaf0 001B0 (v01  AMIER AMI_ERST 20110105 MSFT 00000097)
ACPI: HEST 00000000bf79aca0 000A8 (v01  AMIER ABC_HEST 20110105 MSFT 00000097)
ACPI: Local APIC address 0xfee00000
Setting APIC routing to flat.
SRAT: PXM 0 -> APIC 0 -> Node 0
SRAT: PXM 0 -> APIC 2 -> Node 0
SRAT: PXM 0 -> APIC 4 -> Node 0
SRAT: PXM 0 -> APIC 16 -> Node 0
SRAT: PXM 0 -> APIC 18 -> Node 0
SRAT: PXM 0 -> APIC 20 -> Node 0
SRAT: PXM 0 -> APIC 1 -> Node 0
SRAT: PXM 0 -> APIC 3 -> Node 0
SRAT: PXM 0 -> APIC 5 -> Node 0
SRAT: PXM 0 -> APIC 17 -> Node 0
SRAT: PXM 0 -> APIC 19 -> Node 0
SRAT: PXM 0 -> APIC 21 -> Node 0
SRAT: PXM 1 -> APIC 32 -> Node 1
SRAT: PXM 1 -> APIC 34 -> Node 1
SRAT: PXM 1 -> APIC 36 -> Node 1
SRAT: PXM 1 -> APIC 48 -> Node 1
SRAT: PXM 1 -> APIC 50 -> Node 1
SRAT: PXM 1 -> APIC 52 -> Node 1
SRAT: PXM 1 -> APIC 33 -> Node 1
SRAT: PXM 1 -> APIC 35 -> Node 1
SRAT: PXM 1 -> APIC 37 -> Node 1
SRAT: PXM 1 -> APIC 49 -> Node 1
SRAT: PXM 1 -> APIC 51 -> Node 1
SRAT: PXM 1 -> APIC 53 -> Node 1
SRAT: Node 0 PXM 0 0-a0000
SRAT: Node 0 PXM 0 100000-c0000000
SRAT: Node 0 PXM 0 100000000-c40000000
SRAT: Node 1 PXM 1 c40000000-1840000000
NUMA: Allocated memnodemap from 12040 - 42880
NUMA: Using 20 for the hash shift.
Bootmem setup node 0 0000000000000000-0000000c40000000
  NODE_DATA [0000000000042880 - 000000000007687f]
  bootmap [0000000000100000 -  0000000000287fff] pages 188
(9 early reservations) ==> bootmem [0000000000 - 0c40000000]
  #0 [0000000000 - 0000001000]   BIOS data page ==> [0000000000 - 0000001000]
  #1 [0000006000 - 0000008000]       TRAMPOLINE ==> [0000006000 - 0000008000]
  #2 [0001000000 - 0002020aa4]    TEXT DATA BSS ==> [0001000000 - 0002020aa4]
  #3 [0037045000 - 0037fef0c0]          RAMDISK ==> [0037045000 - 0037fef0c0]
  #4 [0000098800 - 0000100000]    BIOS reserved ==> [0000098800 - 0000100000]
  #5 [0002021000 - 000202127d]              BRK ==> [0002021000 - 000202127d]
  #6 [0000010000 - 0000012000]          PGTABLE ==> [0000010000 - 0000012000]
  #7 [0000012000 - 0000012030]        ACPI SLIT ==> [0000012000 - 0000012030]
  #8 [0000012040 - 0000042880]       MEMNODEMAP ==> [0000012040 - 0000042880]
Bootmem setup node 1 0000000c40000000-0000001840000000
  NODE_DATA [0000000c40000040 - 0000000c4003403f]
  bootmap [0000000c40035000 -  0000000c401b4fff] pages 180
(9 early reservations) ==> bootmem [0c40000000 - 1840000000]
  #0 [0000000000 - 0000001000]   BIOS data page
  #1 [0000006000 - 0000008000]       TRAMPOLINE
  #2 [0001000000 - 0002020aa4]    TEXT DATA BSS
  #3 [0037045000 - 0037fef0c0]          RAMDISK
  #4 [0000098800 - 0000100000]    BIOS reserved
  #5 [0002021000 - 000202127d]              BRK
  #6 [0000010000 - 0000012000]          PGTABLE
  #7 [0000012000 - 0000012030]        ACPI SLIT
  #8 [0000012040 - 0000042880]       MEMNODEMAP
found SMP MP-table at [ffff8800000ff780] ff780
Reserving 135MB of memory at 48MB for crashkernel (System RAM: 99328MB)
 [ffffea0000000000-ffffea000f7fffff] PMD -> [ffff880028600000-ffff880036ffffff] on node 0
 [ffffea000f800000-ffffea002adfffff] PMD -> [ffff880038000000-ffff8800535fffff] on node 0
 [ffffea002ae00000-ffffea003fffffff] PMD -> [ffff880c40200000-ffff880c553fffff] on node 1
 [ffffea0040000000-ffffea0054dfffff] PMD -> [ffff880c55600000-ffff880c6a3fffff] on node 1
Zone PFN ranges:
  DMA      0x00000010 -> 0x00001000
  DMA32    0x00001000 -> 0x00100000
  Normal   0x00100000 -> 0x01840000
Movable zone start PFN for each node
early_node_map[4] active PFN ranges
    0: 0x00000010 -> 0x00000098
    0: 0x00000100 -> 0x000bf780
    0: 0x00100000 -> 0x00c40000
    1: 0x00c40000 -> 0x01840000
On node 0 totalpages: 12580616
  DMA zone: 56 pages used for memmap
  DMA zone: 156 pages reserved
  DMA zone: 3764 pages, LIFO batch:0
  DMA32 zone: 14280 pages used for memmap
  DMA32 zone: 765880 pages, LIFO batch:31
  Normal zone: 161280 pages used for memmap
  Normal zone: 11635200 pages, LIFO batch:31
On node 1 totalpages: 12582912
  Normal zone: 172032 pages used for memmap
  Normal zone: 12410880 pages, LIFO batch:31
ACPI: PM-Timer IO Port: 0x808
ACPI: Local APIC address 0xfee00000
Setting APIC routing to flat.
ACPI: LAPIC (acpi_id[0x01] lapic_id[0x00] enabled)
ACPI: LAPIC (acpi_id[0x02] lapic_id[0x02] enabled)
ACPI: LAPIC (acpi_id[0x03] lapic_id[0x04] enabled)
ACPI: LAPIC (acpi_id[0x04] lapic_id[0x10] enabled)
ACPI: LAPIC (acpi_id[0x05] lapic_id[0x12] enabled)
ACPI: LAPIC (acpi_id[0x06] lapic_id[0x14] enabled)
ACPI: LAPIC (acpi_id[0x07] lapic_id[0x20] enabled)
ACPI: LAPIC (acpi_id[0x08] lapic_id[0x22] enabled)
ACPI: LAPIC (acpi_id[0x09] lapic_id[0x24] enabled)
ACPI: LAPIC (acpi_id[0x0a] lapic_id[0x30] enabled)
ACPI: LAPIC (acpi_id[0x0b] lapic_id[0x32] enabled)
ACPI: LAPIC (acpi_id[0x0c] lapic_id[0x34] enabled)
ACPI: LAPIC (acpi_id[0x0d] lapic_id[0x01] enabled)
ACPI: LAPIC (acpi_id[0x0e] lapic_id[0x03] enabled)
ACPI: LAPIC (acpi_id[0x0f] lapic_id[0x05] enabled)
ACPI: LAPIC (acpi_id[0x10] lapic_id[0x11] enabled)
ACPI: LAPIC (acpi_id[0x11] lapic_id[0x13] enabled)
ACPI: LAPIC (acpi_id[0x12] lapic_id[0x15] enabled)
ACPI: LAPIC (acpi_id[0x13] lapic_id[0x21] enabled)
ACPI: LAPIC (acpi_id[0x14] lapic_id[0x23] enabled)
ACPI: LAPIC (acpi_id[0x15] lapic_id[0x25] enabled)
ACPI: LAPIC (acpi_id[0x16] lapic_id[0x31] enabled)
ACPI: LAPIC (acpi_id[0x17] lapic_id[0x33] enabled)
ACPI: LAPIC (acpi_id[0x18] lapic_id[0x35] enabled)
ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])
ACPI: IOAPIC (id[0x06] address[0xfec00000] gsi_base[0])
IOAPIC[0]: apic_id 6, version 32, address 0xfec00000, GSI 0-23
ACPI: IOAPIC (id[0x07] address[0xfec8a000] gsi_base[24])
IOAPIC[1]: apic_id 7, version 32, address 0xfec8a000, GSI 24-47
ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)
ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
ACPI: IRQ0 used by override.
ACPI: IRQ2 used by override.
ACPI: IRQ9 used by override.
Using ACPI (MADT) for SMP configuration information
ACPI: HPET id: 0x8086a301 base: 0xfed00000
SMP: Allowing 24 CPUs, 0 hotplug CPUs
nr_irqs_gsi: 48
PM: Registered nosave memory: 0000000000098000 - 0000000000099000
PM: Registered nosave memory: 0000000000099000 - 00000000000a0000
PM: Registered nosave memory: 00000000000a0000 - 00000000000e4000
PM: Registered nosave memory: 00000000000e4000 - 0000000000100000
PM: Registered nosave memory: 00000000bf780000 - 00000000bf78e000
PM: Registered nosave memory: 00000000bf78e000 - 00000000bf790000
PM: Registered nosave memory: 00000000bf790000 - 00000000bf79e000
PM: Registered nosave memory: 00000000bf79e000 - 00000000bf7d0000
PM: Registered nosave memory: 00000000bf7d0000 - 00000000bf7e0000
PM: Registered nosave memory: 00000000bf7e0000 - 00000000bf7ec000
PM: Registered nosave memory: 00000000bf7ec000 - 00000000c0000000
PM: Registered nosave memory: 00000000c0000000 - 00000000e0000000
PM: Registered nosave memory: 00000000e0000000 - 00000000f0000000
PM: Registered nosave memory: 00000000f0000000 - 00000000fee00000
PM: Registered nosave memory: 00000000fee00000 - 00000000fee01000
PM: Registered nosave memory: 00000000fee01000 - 00000000ffc00000
PM: Registered nosave memory: 00000000ffc00000 - 0000000100000000
Allocating PCI resources starting at c0000000 (gap: c0000000:20000000)
Booting paravirtualized kernel on bare hardware
NR_CPUS:4096 nr_cpumask_bits:24 nr_cpu_ids:24 nr_node_ids:2
PERCPU: Embedded 31 pages/cpu @ffff880028200000 s94872 r8192 d23912 u131072
pcpu-alloc: s94872 r8192 d23912 u131072 alloc=1*2097152
pcpu-alloc: [0] 00 01 02 03 04 05 12 13 14 15 16 17 -- -- -- -- 
pcpu-alloc: [1] 06 07 08 09 10 11 18 19 20 21 22 23 -- -- -- -- 
Built 2 zonelists in Zone order, mobility grouping on.  Total pages: 24815724
Policy zone: Normal
Kernel command line: ro root=/dev/mapper/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX rd_NO_LUKS LANG=ru_RU.UTF-8 rd_NO_MD quiet SYSFONT=latarcyrheb-sun16 rhgb crashkernel=135M@0M rd_LVM_LV=vg_rosabuildclients004/lv_swap  KEYBOARDTYPE=pc KEYTABLE=us rd_LVM_LV=vg_rosabuildclients004/lv_root rd_NO_DM
PID hash table entries: 4096 (order: 3, 32768 bytes)
Checking aperture...
No AGP bridge found
PCI-DMA: Using software bounce buffering for IO (SWIOTLB)
Placing 64MB software IO TLB between ffff880020000000 - ffff880024000000
software IO TLB at phys 0x20000000 - 0x24000000
Memory: 99036932k/101711872k available (5326k kernel code, 1057760k absent, 1617180k reserved, 7012k data, 1280k init)
Hierarchical RCU implementation.
NR_IRQS:33024 nr_irqs:1008
Extended CMOS year: 2000
Console: colour VGA+ 80x25
console [tty0] enabled
allocated 402653184 bytes of page_cgroup
please try 'cgroup_disable=memory' option if you don't want memory cgroups
hpet clockevent registered
Fast TSC calibration using PIT
Detected 2399.844 MHz processor.
Calibrating delay loop (skipped), value calculated using timer frequency.. 4799.68 BogoMIPS (lpj=2399844)
pid_max: default: 32768 minimum: 301
Security Framework initialized
SELinux:  Initializing.
SELinux:  Starting in permissive mode
Dentry cache hash table entries: 16777216 (order: 15, 134217728 bytes)
Inode-cache hash table entries: 8388608 (order: 14, 67108864 bytes)
Mount-cache hash table entries: 256
Initializing cgroup subsys ns
Initializing cgroup subsys cpuacct
Initializing cgroup subsys memory
Initializing cgroup subsys devices
Initializing cgroup subsys freezer
Initializing cgroup subsys net_cls
Initializing cgroup subsys blkio
Initializing cgroup subsys perf_event
Initializing cgroup subsys net_prio
CPU: Physical Processor ID: 0
CPU: Processor Core ID: 0
mce: CPU supports 9 MCE banks
CPU0: Thermal monitoring enabled (TM1)
using mwait in idle threads.
ACPI: Core revision 20090903
ftrace: converting mcount calls to 0f 1f 44 00 00
ftrace: allocating 21777 entries in 86 pages
APIC routing finalized to physical flat.
..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1
CPU0: Intel(R) Xeon(R) CPU           E5645  @ 2.40GHz stepping 02
Performance Events: PEBS fmt1+, 16-deep LBR, Westmere events, Intel PMU driver.
CPUID marked event: 'bus cycles' unavailable
... version:                3
... bit width:              48
... generic registers:      4
... value mask:             0000ffffffffffff
... max period:             000000007fffffff
... fixed-purpose events:   3
... event mask:             000000070000000f
NMI watchdog enabled, takes one hw-pmu counter.
Booting Node   0, Processors  #1 #2 #3 #4 #5 Ok.
Booting Node   1, Processors  #6 #7 #8 #9 #10 #11 Ok.
Booting Node   0, Processors  #12 #13 #14 #15 #16 #17 Ok.
Booting Node   1, Processors  #18 #19 #20 #21 #22 #23 Ok.
Brought up 24 CPUs
Total of 24 processors activated (115194.98 BogoMIPS).
sizeof(vma)=200 bytes
sizeof(page)=56 bytes
sizeof(inode)=592 bytes
sizeof(dentry)=192 bytes
sizeof(ext3inode)=800 bytes
sizeof(buffer_head)=104 bytes
sizeof(skbuff)=232 bytes
sizeof(task_struct)=2648 bytes
devtmpfs: initialized
PM: Registering ACPI NVS region at bf79e000 (204800 bytes)
regulator: core version 0.5
NET: Registered protocol family 16
ACPI: bus type pci registered
PCI: MCFG configuration 0: base e0000000 segment 0 buses 0 - 255
PCI: MCFG area at e0000000 reserved in E820
PCI: Using MMCONFIG at e0000000 - efffffff
PCI: Using configuration type 1 for base access
bio: create slab <bio-0> at 0
ACPI: EC: Look up EC in DSDT
ACPI Warning for \_SB_._OSC: Return type mismatch - found Integer, expected Buffer (20090903/nspredef-1018)
\_SB_:_OSC evaluation returned wrong type
_OSC request data:1 1f 
ACPI: Executed 1 blocks of module-level executable AML code
ACPI: Interpreter enabled
ACPI: (supports S0 S1 S4 S5)
ACPI: Using IOAPIC for interrupt routing
ACPI Warning: Incorrect checksum in table [OEMB] - 90, should be 8D (20090903/tbutils-314)
ACPI: No dock devices found.
HEST: Table parsing has been initialized.
PCI: Using host bridge windows from ACPI; if necessary, use "pci=nocrs" and report a bug
ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])
pci_root PNP0A08:00: host bridge window [io  0x0000-0x03af]
pci_root PNP0A08:00: host bridge window [io  0x03e0-0x0cf7]
pci_root PNP0A08:00: host bridge window [io  0x03b0-0x03bb]
pci_root PNP0A08:00: host bridge window [io  0x03c0-0x03df]
pci_root PNP0A08:00: host bridge window [io  0x0d00-0xefff]
pci_root PNP0A08:00: host bridge window [io  0xf000-0xffff]
pci_root PNP0A08:00: host bridge window [mem 0x000a0000-0x000bffff]
pci_root PNP0A08:00: host bridge window [mem 0x000d0000-0x000dffff]
pci_root PNP0A08:00: host bridge window [mem 0xc0000000-0xdfffffff]
pci_root PNP0A08:00: host bridge window [mem 0xf0000000-0xfed8ffff]
pci_root PNP0A08:00: host bridge window [mem 0xfed40000-0xfed44fff]
pci_root PNP0A08:00: host bridge window expanded to [mem 0xf0000000-0xfed8ffff]; [mem 0xfed40000-0xfed44fff] ignored
pci_root PNP0A08:00: ignoring host bridge window [mem 0x000d0000-0x000dffff] (conflicts with Adapter ROM [mem 0x000ca000-0x000d01ff])
PCI host bridge to bus 0000:00
pci_bus 0000:00: root bus resource [io  0x0000-0x03af]
pci_bus 0000:00: root bus resource [io  0x03e0-0x0cf7]
pci_bus 0000:00: root bus resource [io  0x03b0-0x03bb]
pci_bus 0000:00: root bus resource [io  0x03c0-0x03df]
pci_bus 0000:00: root bus resource [io  0x0d00-0xefff]
pci_bus 0000:00: root bus resource [io  0xf000-0xffff]
pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff]
pci_bus 0000:00: root bus resource [mem 0xc0000000-0xdfffffff]
pci_bus 0000:00: root bus resource [mem 0xf0000000-0xfed8ffff]
pci 0000:00:00.0: PME# supported from D0 D3hot D3cold
pci 0000:00:00.0: PME# disabled
pci 0000:00:01.0: PME# supported from D0 D3hot D3cold
pci 0000:00:01.0: PME# disabled
pci 0000:00:03.0: PME# supported from D0 D3hot D3cold
pci 0000:00:03.0: PME# disabled
pci 0000:00:07.0: PME# supported from D0 D3hot D3cold
pci 0000:00:07.0: PME# disabled
pci 0000:00:09.0: PME# supported from D0 D3hot D3cold
pci 0000:00:09.0: PME# disabled
pci 0000:00:13.0: reg 10: [mem 0xfec8a000-0xfec8afff]
pci 0000:00:13.0: PME# supported from D0 D3hot D3cold
pci 0000:00:13.0: PME# disabled
pci 0000:00:16.0: reg 10: [mem 0xfbef8000-0xfbefbfff 64bit]
pci 0000:00:16.1: reg 10: [mem 0xfbef4000-0xfbef7fff 64bit]
pci 0000:00:16.2: reg 10: [mem 0xfbef0000-0xfbef3fff 64bit]
pci 0000:00:16.3: reg 10: [mem 0xfbeec000-0xfbeeffff 64bit]
pci 0000:00:16.4: reg 10: [mem 0xfbee8000-0xfbeebfff 64bit]
pci 0000:00:16.5: reg 10: [mem 0xfbee4000-0xfbee7fff 64bit]
pci 0000:00:16.6: reg 10: [mem 0xfbee0000-0xfbee3fff 64bit]
pci 0000:00:16.7: reg 10: [mem 0xfbedc000-0xfbedffff 64bit]
pci 0000:00:1a.0: reg 20: [io  0xbc00-0xbc1f]
pci 0000:00:1a.1: reg 20: [io  0xb880-0xb89f]
pci 0000:00:1a.2: reg 20: [io  0xb800-0xb81f]
pci 0000:00:1a.7: reg 10: [mem 0xfbeda000-0xfbeda3ff]
pci 0000:00:1a.7: PME# supported from D0 D3hot D3cold
pci 0000:00:1a.7: PME# disabled
pci 0000:00:1b.0: reg 10: [mem 0xfbed4000-0xfbed7fff 64bit]
pci 0000:00:1b.0: PME# supported from D0 D3hot D3cold
pci 0000:00:1b.0: PME# disabled
pci 0000:00:1c.0: PME# supported from D0 D3hot D3cold
pci 0000:00:1c.0: PME# disabled
pci 0000:00:1c.4: PME# supported from D0 D3hot D3cold
pci 0000:00:1c.4: PME# disabled
pci 0000:00:1c.5: PME# supported from D0 D3hot D3cold
pci 0000:00:1c.5: PME# disabled
pci 0000:00:1d.0: reg 20: [io  0xb480-0xb49f]
pci 0000:00:1d.1: reg 20: [io  0xb400-0xb41f]
pci 0000:00:1d.2: reg 20: [io  0xb080-0xb09f]
pci 0000:00:1d.7: reg 10: [mem 0xfbed8000-0xfbed83ff]
pci 0000:00:1d.7: PME# supported from D0 D3hot D3cold
pci 0000:00:1d.7: PME# disabled
pci 0000:00:1f.0: quirk: [io  0x0800-0x087f] claimed by ICH6 ACPI/GPIO/TCO
pci 0000:00:1f.0: quirk: [io  0x0500-0x053f] claimed by ICH6 GPIO
pci 0000:00:1f.0: ICH7 LPC Generic IO decode 1 PIO at 0a00 (mask 00ff)
pci 0000:00:1f.0: ICH7 LPC Generic IO decode 2 PIO at 4700 (mask 00ff)
pci 0000:00:1f.0: ICH7 LPC Generic IO decode 4 PIO at 0ca0 (mask 000f)
pci 0000:00:1f.2: reg 10: [io  0xa480-0xa487]
pci 0000:00:1f.2: reg 14: [io  0xb000-0xb003]
pci 0000:00:1f.2: reg 18: [io  0xac00-0xac07]
pci 0000:00:1f.2: reg 1c: [io  0xa880-0xa883]
pci 0000:00:1f.2: reg 20: [io  0xa800-0xa81f]
pci 0000:00:1f.2: reg 24: [mem 0xfbed2000-0xfbed27ff]
pci 0000:00:1f.2: PME# supported from D3hot
pci 0000:00:1f.2: PME# disabled
pci 0000:00:1f.3: reg 10: [mem 0xfbed0000-0xfbed00ff 64bit]
pci 0000:00:1f.3: reg 20: [io  0x0400-0x041f]
pci 0000:00:01.0: PCI bridge to [bus 01-01]
pci 0000:00:01.0:   bridge window [io  0xf000-0x0000] (disabled)
pci 0000:00:01.0:   bridge window [mem 0xfff00000-0x000fffff] (disabled)
pci 0000:00:01.0:   bridge window [mem 0xfff00000-0x000fffff pref] (disabled)
pci 0000:00:03.0: PCI bridge to [bus 02-02]
pci 0000:00:03.0:   bridge window [io  0xf000-0x0000] (disabled)
pci 0000:00:03.0:   bridge window [mem 0xfff00000-0x000fffff] (disabled)
pci 0000:00:03.0:   bridge window [mem 0xfff00000-0x000fffff pref] (disabled)
pci 0000:00:07.0: PCI bridge to [bus 03-03]
pci 0000:00:07.0:   bridge window [io  0xf000-0x0000] (disabled)
pci 0000:00:07.0:   bridge window [mem 0xfff00000-0x000fffff] (disabled)
pci 0000:00:07.0:   bridge window [mem 0xfff00000-0x000fffff pref] (disabled)
pci 0000:04:00.0: reg 10: [io  0xc000-0xc0ff]
pci 0000:04:00.0: reg 14: [mem 0xfbb9c000-0xfbb9ffff 64bit]
pci 0000:04:00.0: reg 1c: [mem 0xfbbc0000-0xfbbfffff 64bit]
pci 0000:04:00.0: reg 30: [mem 0xfbba0000-0xfbbbffff pref]
pci 0000:04:00.0: supports D1 D2
pci 0000:00:09.0: PCI bridge to [bus 04-04]
pci 0000:00:09.0:   bridge window [io  0xc000-0xcfff]
pci 0000:00:09.0:   bridge window [mem 0xfbb00000-0xfbbfffff]
pci 0000:00:09.0:   bridge window [mem 0xfff00000-0x000fffff pref] (disabled)
pci 0000:00:1c.0: PCI bridge to [bus 05-05]
pci 0000:00:1c.0:   bridge window [io  0xf000-0x0000] (disabled)
pci 0000:00:1c.0:   bridge window [mem 0xfff00000-0x000fffff] (disabled)
pci 0000:00:1c.0:   bridge window [mem 0xfff00000-0x000fffff pref] (disabled)
pci 0000:06:00.0: reg 10: [mem 0xfbce0000-0xfbcfffff]
pci 0000:06:00.0: reg 18: [io  0xdc00-0xdc1f]
pci 0000:06:00.0: reg 1c: [mem 0xfbcdc000-0xfbcdffff]
pci 0000:06:00.0: PME# supported from D0 D3hot D3cold
pci 0000:06:00.0: PME# disabled
pci 0000:00:1c.4: PCI bridge to [bus 06-06]
pci 0000:00:1c.4:   bridge window [io  0xd000-0xdfff]
pci 0000:00:1c.4:   bridge window [mem 0xfbc00000-0xfbcfffff]
pci 0000:00:1c.4:   bridge window [mem 0xfff00000-0x000fffff pref] (disabled)
pci 0000:07:00.0: reg 10: [mem 0xfbde0000-0xfbdfffff]
pci 0000:07:00.0: reg 18: [io  0xec00-0xec1f]
pci 0000:07:00.0: reg 1c: [mem 0xfbddc000-0xfbddffff]
pci 0000:07:00.0: PME# supported from D0 D3hot D3cold
pci 0000:07:00.0: PME# disabled
pci 0000:00:1c.5: PCI bridge to [bus 07-07]
pci 0000:00:1c.5:   bridge window [io  0xe000-0xefff]
pci 0000:00:1c.5:   bridge window [mem 0xfbd00000-0xfbdfffff]
pci 0000:00:1c.5:   bridge window [mem 0xfff00000-0x000fffff pref] (disabled)
pci 0000:08:01.0: reg 10: [mem 0xf9000000-0xf9ffffff pref]
pci 0000:08:01.0: reg 14: [mem 0xfaffc000-0xfaffffff]
pci 0000:08:01.0: reg 18: [mem 0xfb000000-0xfb7fffff]
pci 0000:00:1e.0: PCI bridge to [bus 08-08] (subtractive decode)
pci 0000:00:1e.0:   bridge window [io  0xf000-0x0000] (disabled)
pci 0000:00:1e.0:   bridge window [mem 0xfaf00000-0xfb7fffff]
pci 0000:00:1e.0:   bridge window [mem 0xf9000000-0xf9ffffff 64bit pref]
pci 0000:00:1e.0:   bridge window [io  0x0000-0x03af] (subtractive decode)
pci 0000:00:1e.0:   bridge window [io  0x03e0-0x0cf7] (subtractive decode)
pci 0000:00:1e.0:   bridge window [io  0x03b0-0x03bb] (subtractive decode)
pci 0000:00:1e.0:   bridge window [io  0x03c0-0x03df] (subtractive decode)
pci 0000:00:1e.0:   bridge window [io  0x0d00-0xefff] (subtractive decode)
pci 0000:00:1e.0:   bridge window [io  0xf000-0xffff] (subtractive decode)
pci 0000:00:1e.0:   bridge window [mem 0x000a0000-0x000bffff] (subtractive decode)
pci 0000:00:1e.0:   bridge window [mem 0xc0000000-0xdfffffff] (subtractive decode)
pci 0000:00:1e.0:   bridge window [mem 0xf0000000-0xfed8ffff] (subtractive decode)
pci_bus 0000:00: on NUMA node 0 (pxm 0)
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0._PRT]
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0.NPE1._PRT]
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0.NPE3._PRT]
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0.NPE7._PRT]
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0.NPE9._PRT]
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0.P0P1._PRT]
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0.P0P4._PRT]
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0.P0P8._PRT]
ACPI: PCI Interrupt Routing Table [\_SB_.PCI0.P0P9._PRT]
 pci0000:00: Requesting ACPI _OSC control (0x1d)
Unable to assume _OSC PCIe control. Disabling ASPM
ACPI: PCI Interrupt Link [LNKA] (IRQs 3 4 6 7 10 *11 12 14 15)
ACPI: PCI Interrupt Link [LNKB] (IRQs 3 4 6 7 *10 11 12 14 15)
ACPI: PCI Interrupt Link [LNKC] (IRQs 3 4 6 7 10 11 12 14 *15)
ACPI: PCI Interrupt Link [LNKD] (IRQs 3 4 6 7 10 11 12 *14 15)
ACPI: PCI Interrupt Link [LNKE] (IRQs 3 4 6 7 10 11 12 14 15) *0, disabled.
ACPI: PCI Interrupt Link [LNKF] (IRQs 3 4 6 *7 10 11 12 14 15)
ACPI: PCI Interrupt Link [LNKG] (IRQs 3 4 *6 7 10 11 12 14 15)
ACPI: PCI Interrupt Link [LNKH] (IRQs 3 4 6 7 *10 11 12 14 15)
vgaarb: device added: PCI:0000:08:01.0,decodes=io+mem,owns=io+mem,locks=none
vgaarb: loaded
vgaarb: bridge control possible 0000:08:01.0
SCSI subsystem initialized
libata version 3.00 loaded.
usbcore: registered new interface driver usbfs
usbcore: registered new interface driver hub
usbcore: registered new device driver usb
PCI: Using ACPI for IRQ routing
PCI: old code would have set cacheline size to 32 bytes, but clflush_size = 64
PCI: pci_cache_line_size set to 64 bytes
NetLabel: Initializing
NetLabel:  domain hash size = 128
NetLabel:  protocols = UNLABELED CIPSOv4
NetLabel:  unlabeled traffic allowed by default
HPET: 4 timers in total, 0 timers will be used for per-cpu timer
hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0, 0
hpet0: 4 comparators, 64-bit 14.318180 MHz counter
Switching to clocksource hpet
pnp: PnP ACPI init
ACPI: bus type pnp registered
pnp 00:00: [io  0x0cf8-0x0cff]
pnp 00:00: [mem 0xfed40000-0xfed44fff]
pnp 00:00: Plug and Play ACPI device, IDs PNP0a08 PNP0a03 (active)
pnp 00:01: [mem 0xfed1c000-0xfed1ffff]
pnp 00:01: Plug and Play ACPI device, IDs PNP0c01 (active)
pnp 00:02: [dma 4]
pnp 00:02: [io  0x0000-0x000f]
pnp 00:02: [io  0x0081-0x0083]
pnp 00:02: [io  0x0087]
pnp 00:02: [io  0x0089-0x008b]
pnp 00:02: [io  0x008f]
pnp 00:02: [io  0x00c0-0x00df]
pnp 00:02: Plug and Play ACPI device, IDs PNP0200 (active)
pnp 00:03: [io  0x0070-0x0071]
pnp 00:03: [irq 8]
pnp 00:03: Plug and Play ACPI device, IDs PNP0b00 (active)
pnp 00:04: [io  0x0061]
pnp 00:04: Plug and Play ACPI device, IDs PNP0800 (active)
pnp 00:05: [io  0x00f0-0x00ff]
pnp 00:05: [irq 13]
pnp 00:05: Plug and Play ACPI device, IDs PNP0c04 (active)
pnp 00:06: [io  0x0000-0xffffffffffffffff disabled]
pnp 00:06: [io  0x0000-0xffffffffffffffff disabled]
pnp 00:06: [io  0x0a10-0x0a1f]
pnp 00:06: Plug and Play ACPI device, IDs PNP0c02 (active)
pnp 00:07: [io  0x03f8-0x03ff]
pnp 00:07: [irq 4]
pnp 00:07: [dma 0 disabled]
pnp 00:07: Plug and Play ACPI device, IDs PNP0501 (active)
pnp 00:08: [io  0x02f8-0x02ff]
pnp 00:08: [irq 3]
pnp 00:08: [dma 0 disabled]
pnp 00:08: Plug and Play ACPI device, IDs PNP0501 (active)
pnp 00:09: [io  0x0010-0x001f]
pnp 00:09: [io  0x0022-0x003f]
pnp 00:09: [io  0x0044-0x004f]
pnp 00:09: [io  0x0050-0x005f]
pnp 00:09: [io  0x0062-0x0063]
pnp 00:09: [io  0x0065-0x006f]
pnp 00:09: [io  0x0072-0x007f]
pnp 00:09: [io  0x0080]
pnp 00:09: [io  0x0084-0x0086]
pnp 00:09: [io  0x0088]
pnp 00:09: [io  0x008c-0x008e]
pnp 00:09: [io  0x0090-0x009f]
pnp 00:09: [io  0x00a2-0x00bf]
pnp 00:09: [io  0x00e0-0x00ef]
pnp 00:09: [io  0x0ca2-0x0ca3]
pnp 00:09: [io  0x0cf8-0x0cff]
pnp 00:09: [io  0x04d0-0x04d1]
pnp 00:09: [mem 0x00000400-0x000004ff]
pnp 00:09: [io  0x0800-0x087f]
pnp 00:09: [io  0x0000-0xffffffffffffffff disabled]
pnp 00:09: [io  0x0500-0x057f]
pnp 00:09: [mem 0xfed1c000-0xfed1ffff]
pnp 00:09: [mem 0xfed20000-0xfed3ffff]
pnp 00:09: [mem 0xfed40000-0xfed8ffff]
pnp 00:09: Plug and Play ACPI device, IDs PNP0c02 (active)
pnp 00:0a: [mem 0xfed00000-0xfed003ff]
pnp 00:0a: Plug and Play ACPI device, IDs PNP0103 (active)
pnp 00:0b: [io  0x0060]
pnp 00:0b: [io  0x0064]
pnp 00:0b: [mem 0xfec00000-0xfec00fff]
pnp 00:0b: [mem 0xfee00000-0xfee00fff]
pnp 00:0b: Plug and Play ACPI device, IDs PNP0c02 (active)
pnp 00:0c: [mem 0xe0000000-0xefffffff]
pnp 00:0c: Plug and Play ACPI device, IDs PNP0c02 (active)
pnp 00:0d: [mem 0x000c0000-0x000cffff]
pnp 00:0d: [mem 0x000e0000-0x000fffff]
pnp 00:0d: [mem 0xfed90000-0xffffffff]
pnp 00:0d: Plug and Play ACPI device, IDs PNP0c01 (active)
pnp: PnP ACPI: found 14 devices
ACPI: ACPI bus type pnp unregistered
system 00:01: [mem 0xfed1c000-0xfed1ffff] has been reserved
system 00:06: [io  0x0a10-0x0a1f] has been reserved
system 00:09: [io  0x0ca2-0x0ca3] has been reserved
system 00:09: [io  0x0cf8-0x0cff] could not be reserved
system 00:09: [io  0x04d0-0x04d1] has been reserved
system 00:09: [io  0x0800-0x087f] has been reserved
system 00:09: [io  0x0500-0x057f] could not be reserved
system 00:09: [mem 0x00000400-0x000004ff] could not be reserved
system 00:09: [mem 0xfed1c000-0xfed1ffff] has been reserved
system 00:09: [mem 0xfed20000-0xfed3ffff] has been reserved
system 00:09: [mem 0xfed40000-0xfed8ffff] has been reserved
system 00:0b: [mem 0xfec00000-0xfec00fff] could not be reserved
system 00:0b: [mem 0xfee00000-0xfee00fff] has been reserved
system 00:0c: [mem 0xe0000000-0xefffffff] has been reserved
system 00:0d: [mem 0x000c0000-0x000cffff] could not be reserved
system 00:0d: [mem 0x000e0000-0x000fffff] could not be reserved
system 00:0d: [mem 0xfed90000-0xffffffff] could not be reserved
PCI: max bus depth: 1 pci_try_num: 2
pci 0000:00:1c.5: BAR 15: assigned [mem 0xc0000000-0xc01fffff 64bit pref]
pci 0000:00:1c.4: BAR 15: assigned [mem 0xc0200000-0xc03fffff 64bit pref]
pci 0000:00:1c.0: BAR 14: assigned [mem 0xc0400000-0xc05fffff]
pci 0000:00:1c.0: BAR 15: assigned [mem 0xc0600000-0xc07fffff 64bit pref]
pci 0000:00:1c.0: BAR 13: assigned [io  0x1000-0x1fff]
pci 0000:00:01.0: PCI bridge to [bus 01-01]
pci 0000:00:01.0: PCI bridge to [bus 01-01]
pci 0000:00:01.0:   bridge window [io  disabled]
pci 0000:00:01.0:   bridge window [mem disabled]
pci 0000:00:01.0:   bridge window [mem pref disabled]
pci 0000:00:03.0: PCI bridge to [bus 02-02]
pci 0000:00:03.0: PCI bridge to [bus 02-02]
pci 0000:00:03.0:   bridge window [io  disabled]
pci 0000:00:03.0:   bridge window [mem disabled]
pci 0000:00:03.0:   bridge window [mem pref disabled]
pci 0000:00:07.0: PCI bridge to [bus 03-03]
pci 0000:00:07.0: PCI bridge to [bus 03-03]
pci 0000:00:07.0:   bridge window [io  disabled]
pci 0000:00:07.0:   bridge window [mem disabled]
pci 0000:00:07.0:   bridge window [mem pref disabled]
pci 0000:00:09.0: PCI bridge to [bus 04-04]
pci 0000:00:09.0: PCI bridge to [bus 04-04]
pci 0000:00:09.0:   bridge window [io  0xc000-0xcfff]
pci 0000:00:09.0:   bridge window [mem 0xfbb00000-0xfbbfffff]
pci 0000:00:09.0:   bridge window [mem pref disabled]
pci 0000:00:1c.0: PCI bridge to [bus 05-05]
pci 0000:00:1c.0: PCI bridge to [bus 05-05]
pci 0000:00:1c.0:   bridge window [io  0x1000-0x1fff]
pci 0000:00:1c.0:   bridge window [mem 0xc0400000-0xc05fffff]
pci 0000:00:1c.0:   bridge window [mem 0xc0600000-0xc07fffff 64bit pref]
pci 0000:00:1c.4: PCI bridge to [bus 06-06]
pci 0000:00:1c.4: PCI bridge to [bus 06-06]
pci 0000:00:1c.4:   bridge window [io  0xd000-0xdfff]
pci 0000:00:1c.4:   bridge window [mem 0xfbc00000-0xfbcfffff]
pci 0000:00:1c.4:   bridge window [mem 0xc0200000-0xc03fffff 64bit pref]
pci 0000:00:1c.5: PCI bridge to [bus 07-07]
pci 0000:00:1c.5: PCI bridge to [bus 07-07]
pci 0000:00:1c.5:   bridge window [io  0xe000-0xefff]
pci 0000:00:1c.5:   bridge window [mem 0xfbd00000-0xfbdfffff]
pci 0000:00:1c.5:   bridge window [mem 0xc0000000-0xc01fffff 64bit pref]
pci 0000:00:1e.0: PCI bridge to [bus 08-08]
pci 0000:00:1e.0: PCI bridge to [bus 08-08]
pci 0000:00:1e.0:   bridge window [io  disabled]
pci 0000:00:1e.0:   bridge window [mem 0xfaf00000-0xfb7fffff]
pci 0000:00:1e.0:   bridge window [mem 0xf9000000-0xf9ffffff 64bit pref]
pci 0000:00:01.0: setting latency timer to 64
pci 0000:00:03.0: setting latency timer to 64
pci 0000:00:07.0: setting latency timer to 64
pci 0000:00:09.0: setting latency timer to 64
pci 0000:00:1c.0: enabling device (0104 -> 0107)
  alloc irq_desc for 17 on node 0
  alloc kstat_irqs on node 0
pci 0000:00:1c.0: PCI INT A -> GSI 17 (level, low) -> IRQ 17
pci 0000:00:1c.0: setting latency timer to 64
pci 0000:00:1c.4: PCI INT A -> GSI 17 (level, low) -> IRQ 17
pci 0000:00:1c.4: setting latency timer to 64
  alloc irq_desc for 16 on node 0
  alloc kstat_irqs on node 0
pci 0000:00:1c.5: PCI INT B -> GSI 16 (level, low) -> IRQ 16
pci 0000:00:1c.5: setting latency timer to 64
pci 0000:00:1e.0: setting latency timer to 64
pci_bus 0000:00: resource 4 [io  0x0000-0x03af]
pci_bus 0000:00: resource 5 [io  0x03e0-0x0cf7]
pci_bus 0000:00: resource 6 [io  0x03b0-0x03bb]
pci_bus 0000:00: resource 7 [io  0x03c0-0x03df]
pci_bus 0000:00: resource 8 [io  0x0d00-0xefff]
pci_bus 0000:00: resource 9 [io  0xf000-0xffff]
pci_bus 0000:00: resource 10 [mem 0x000a0000-0x000bffff]
pci_bus 0000:00: resource 11 [mem 0xc0000000-0xdfffffff]
pci_bus 0000:00: resource 12 [mem 0xf0000000-0xfed8ffff]
pci_bus 0000:04: resource 0 [io  0xc000-0xcfff]
pci_bus 0000:04: resource 1 [mem 0xfbb00000-0xfbbfffff]
pci_bus 0000:05: resource 0 [io  0x1000-0x1fff]
pci_bus 0000:05: resource 1 [mem 0xc0400000-0xc05fffff]
pci_bus 0000:05: resource 2 [mem 0xc0600000-0xc07fffff 64bit pref]
pci_bus 0000:06: resource 0 [io  0xd000-0xdfff]
pci_bus 0000:06: resource 1 [mem 0xfbc00000-0xfbcfffff]
pci_bus 0000:06: resource 2 [mem 0xc0200000-0xc03fffff 64bit pref]
pci_bus 0000:07: resource 0 [io  0xe000-0xefff]
pci_bus 0000:07: resource 1 [mem 0xfbd00000-0xfbdfffff]
pci_bus 0000:07: resource 2 [mem 0xc0000000-0xc01fffff 64bit pref]
pci_bus 0000:08: resource 1 [mem 0xfaf00000-0xfb7fffff]
pci_bus 0000:08: resource 2 [mem 0xf9000000-0xf9ffffff 64bit pref]
pci_bus 0000:08: resource 4 [io  0x0000-0x03af]
pci_bus 0000:08: resource 5 [io  0x03e0-0x0cf7]
pci_bus 0000:08: resource 6 [io  0x03b0-0x03bb]
pci_bus 0000:08: resource 7 [io  0x03c0-0x03df]
pci_bus 0000:08: resource 8 [io  0x0d00-0xefff]
pci_bus 0000:08: resource 9 [io  0xf000-0xffff]
pci_bus 0000:08: resource 10 [mem 0x000a0000-0x000bffff]
pci_bus 0000:08: resource 11 [mem 0xc0000000-0xdfffffff]
pci_bus 0000:08: resource 12 [mem 0xf0000000-0xfed8ffff]
NET: Registered protocol family 2
IP route cache hash table entries: 524288 (order: 10, 4194304 bytes)
TCP established hash table entries: 524288 (order: 11, 8388608 bytes)
TCP bind hash table entries: 65536 (order: 8, 1048576 bytes)
TCP: Hash tables configured (established 524288 bind 65536)
TCP reno registered
NET: Registered protocol family 1
pci 0000:00:1a.0: PCI INT A -> GSI 16 (level, low) -> IRQ 16
pci 0000:00:1a.0: PCI INT A disabled
  alloc irq_desc for 21 on node 0
  alloc kstat_irqs on node 0
pci 0000:00:1a.1: PCI INT B -> GSI 21 (level, low) -> IRQ 21
pci 0000:00:1a.1: PCI INT B disabled
  alloc irq_desc for 19 on node 0
  alloc kstat_irqs on node 0
pci 0000:00:1a.2: PCI INT D -> GSI 19 (level, low) -> IRQ 19
pci 0000:00:1a.2: PCI INT D disabled
  alloc irq_desc for 18 on node 0
  alloc kstat_irqs on node 0
pci 0000:00:1a.7: PCI INT C -> GSI 18 (level, low) -> IRQ 18
pci 0000:00:1a.7: PCI INT C disabled
  alloc irq_desc for 23 on node 0
  alloc kstat_irqs on node 0
pci 0000:00:1d.0: PCI INT A -> GSI 23 (level, low) -> IRQ 23
pci 0000:00:1d.0: PCI INT A disabled
pci 0000:00:1d.1: PCI INT B -> GSI 19 (level, low) -> IRQ 19
pci 0000:00:1d.1: PCI INT B disabled
pci 0000:00:1d.2: PCI INT C -> GSI 18 (level, low) -> IRQ 18
pci 0000:00:1d.2: PCI INT C disabled
pci 0000:00:1d.7: PCI INT A -> GSI 23 (level, low) -> IRQ 23
pci 0000:00:1d.7: PCI INT A disabled
pci 0000:08:01.0: Boot video device
Trying to unpack rootfs image as initramfs...
Freeing initrd memory: 16040k freed
audit: initializing netlink socket (disabled)
type=2000 audit(1397825776.653:1): initialized
HugeTLB registered 2 MB page size, pre-allocated 0 pages
VFS: Disk quotas dquot_6.5.2
Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
msgmni has been set to 32768
SELinux:  Registering netfilter hooks
alg: No test for stdrng (krng)
ksign: Installing public key data
Loading keyring
- Added public key E2DDE158B9C43566
- User ID: Red Hat, Inc. (Kernel Module GPG key)
- Added public key D4A26C9CCD09BEDA
- User ID: Red Hat Enterprise Linux Driver Update Program <XXX@XXX>
Block layer SCSI generic (bsg) driver version 0.4 loaded (major 251)
io scheduler noop registered
io scheduler anticipatory registered
io scheduler deadline registered
io scheduler cfq registered (default)
pcieport 0000:00:1c.0: setting latency timer to 64
  alloc irq_desc for 48 on node 0
  alloc kstat_irqs on node 0
pcieport 0000:00:1c.0: irq 48 for MSI/MSI-X
pcieport 0000:00:1c.4: setting latency timer to 64
  alloc irq_desc for 49 on node 0
  alloc kstat_irqs on node 0
pcieport 0000:00:1c.4: irq 49 for MSI/MSI-X
pcieport 0000:00:1c.5: setting latency timer to 64
  alloc irq_desc for 50 on node 0
  alloc kstat_irqs on node 0
pcieport 0000:00:1c.5: irq 50 for MSI/MSI-X
pci_hotplug: PCI Hot Plug PCI Core version: 0.5
pciehp: PCI Express Hot Plug Controller Driver version: 0.4
acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5
intel_idle: MWAIT substates: 0x1120
intel_idle: v0.4 model 0x2C
intel_idle: lapic_timer_reliable_states 0xffffffff
ipmi message handler version 39.2
IPMI System Interface driver.
ipmi_si: probing via SMBIOS
ipmi_si: SMBIOS: io 0xca2 regsize 1 spacing 1 irq 0
ipmi_si: Adding SMBIOS-specified kcs state machine
ipmi_si: Trying SMBIOS-specified kcs state machine at i/o address 0xca2, slave address 0x0, irq 0
ipmi_si: Invalid return from get global enables command, cannot enable the event buffer.
ipmi_si ipmi_si.0: Found new BMC (man_id: 0x00b980, prod_id: 0x0006, dev_id: 0x20)
ipmi_si ipmi_si.0: IPMI kcs interface initialized
input: Power Button as /devices/LNXSYSTM:00/LNXSYBUS:00/PNP0C0C:00/input/input0
ACPI: Power Button [PWRB]
input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input1
ACPI: Power Button [PWRF]
ACPI: acpi_idle yielding to intel_idleACPI: SSDT 00000000bf79e0d0 0477C (v01 DpgPmm  P001Ist 00000011 INTL 20051117)
ACPI: SSDT 00000000bf7a2850 00C69 (v01  PmRef  P001Cst 00003001 INTL 20051117)
ACPI: SSDT 00000000bf7a34c0 00A0A (v01  PmRef  Cpu0Tst 00003000 INTL 20051117)
ACPI Exception: AE_NOT_FOUND, No or invalid critical threshold (20090903/thermal-386)
ERST: Failed to get Error Log Address Range.
[Firmware Warn]: GHES: Poll interval is 0 for generic hardware error source: 1, disabled.
GHES: APEI firmware first mode is enabled by WHEA _OSC.
Non-volatile memory driver v1.3
Linux agpgart interface v0.103
crash memory driver: version 1.1
Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled
serial8250: ttyS0 at I/O 0x3f8 (irq = 4) is a 16550A
serial8250: ttyS1 at I/O 0x2f8 (irq = 3) is a 16550A
00:07: ttyS0 at I/O 0x3f8 (irq = 4) is a 16550A
00:08: ttyS1 at I/O 0x2f8 (irq = 3) is a 16550A
brd: module loaded
loop: module loaded
input: Macintosh mouse button emulation as /devices/virtual/input/input2
Fixed MDIO Bus: probed
ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver
ehci_hcd 0000:00:1a.7: PCI INT C -> GSI 18 (level, low) -> IRQ 18
ehci_hcd 0000:00:1a.7: setting latency timer to 64
ehci_hcd 0000:00:1a.7: EHCI Host Controller
ehci_hcd 0000:00:1a.7: new USB bus registered, assigned bus number 1
ehci_hcd 0000:00:1a.7: debug port 1
ehci_hcd 0000:00:1a.7: cache line size of 64 is not supported
ehci_hcd 0000:00:1a.7: irq 18, io mem 0xfbeda000
ehci_hcd 0000:00:1a.7: USB 2.0 started, EHCI 1.00
usb usb1: New USB device found, idVendor=1d6b, idProduct=0002
usb usb1: New USB device strings: Mfr=3, Product=2, SerialNumber=...
usb usb1: Product: EHCI Host Controller
usb usb1: Manufacturer: Linux 2.6.32-431.11.2.res6.x86_64 ehci_hcd
usb usb1: SerialNumber: ...
usb usb1: configuration #1 chosen from 1 choice
hub 1-0:1.0: USB hub found
hub 1-0:1.0: 6 ports detected
ehci_hcd 0000:00:1d.7: PCI INT A -> GSI 23 (level, low) -> IRQ 23
ehci_hcd 0000:00:1d.7: setting latency timer to 64
ehci_hcd 0000:00:1d.7: EHCI Host Controller
ehci_hcd 0000:00:1d.7: new USB bus registered, assigned bus number 2
ehci_hcd 0000:00:1d.7: debug port 1
ehci_hcd 0000:00:1d.7: cache line size of 64 is not supported
ehci_hcd 0000:00:1d.7: irq 23, io mem 0xfbed8000
ehci_hcd 0000:00:1d.7: USB 2.0 started, EHCI 1.00
usb usb2: New USB device found, idVendor=1d6b, idProduct=0002
usb usb2: New USB device strings: Mfr=3, Product=2, SerialNumber=...
usb usb2: Product: EHCI Host Controller
usb usb2: Manufacturer: Linux 2.6.32-431.11.2.res6.x86_64 ehci_hcd
usb usb2: SerialNumber: ...
usb usb2: configuration #1 chosen from 1 choice
hub 2-0:1.0: USB hub found
hub 2-0:1.0: 6 ports detected
ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver
uhci_hcd: USB Universal Host Controller Interface driver
uhci_hcd 0000:00:1a.0: PCI INT A -> GSI 16 (level, low) -> IRQ 16
uhci_hcd 0000:00:1a.0: setting latency timer to 64
uhci_hcd 0000:00:1a.0: UHCI Host Controller
uhci_hcd 0000:00:1a.0: new USB bus registered, assigned bus number 3
uhci_hcd 0000:00:1a.0: irq 16, io base 0x0000bc00
usb usb3: New USB device found, idVendor=1d6b, idProduct=0001
usb usb3: New USB device strings: Mfr=3, Product=2, SerialNumber=...
usb usb3: Product: UHCI Host Controller
usb usb3: Manufacturer: Linux 2.6.32-431.11.2.res6.x86_64 uhci_hcd
usb usb3: SerialNumber: ...
usb usb3: configuration #1 chosen from 1 choice
hub 3-0:1.0: USB hub found
hub 3-0:1.0: 2 ports detected
uhci_hcd 0000:00:1a.1: PCI INT B -> GSI 21 (level, low) -> IRQ 21
uhci_hcd 0000:00:1a.1: setting latency timer to 64
uhci_hcd 0000:00:1a.1: UHCI Host Controller
uhci_hcd 0000:00:1a.1: new USB bus registered, assigned bus number 4
uhci_hcd 0000:00:1a.1: irq 21, io base 0x0000b880
usb usb4: New USB device found, idVendor=1d6b, idProduct=0001
usb usb4: New USB device strings: Mfr=3, Product=2, SerialNumber=...
usb usb4: Product: UHCI Host Controller
usb usb4: Manufacturer: Linux 2.6.32-431.11.2.res6.x86_64 uhci_hcd
usb usb4: SerialNumber: ...
usb usb4: configuration #1 chosen from 1 choice
hub 4-0:1.0: USB hub found
hub 4-0:1.0: 2 ports detected
uhci_hcd 0000:00:1a.2: PCI INT D -> GSI 19 (level, low) -> IRQ 19
uhci_hcd 0000:00:1a.2: setting latency timer to 64
uhci_hcd 0000:00:1a.2: UHCI Host Controller
uhci_hcd 0000:00:1a.2: new USB bus registered, assigned bus number 5
uhci_hcd 0000:00:1a.2: irq 19, io base 0x0000b800
usb usb5: New USB device found, idVendor=1d6b, idProduct=0001
usb usb5: New USB device strings: Mfr=3, Product=2, SerialNumber=...
usb usb5: Product: UHCI Host Controller
usb usb5: Manufacturer: Linux 2.6.32-431.11.2.res6.x86_64 uhci_hcd
usb usb5: SerialNumber: ...
usb usb5: configuration #1 chosen from 1 choice
hub 5-0:1.0: USB hub found
hub 5-0:1.0: 2 ports detected
uhci_hcd 0000:00:1d.0: PCI INT A -> GSI 23 (level, low) -> IRQ 23
uhci_hcd 0000:00:1d.0: setting latency timer to 64
uhci_hcd 0000:00:1d.0: UHCI Host Controller
uhci_hcd 0000:00:1d.0: new USB bus registered, assigned bus number 6
uhci_hcd 0000:00:1d.0: irq 23, io base 0x0000b480
usb usb6: New USB device found, idVendor=1d6b, idProduct=0001
usb usb6: New USB device strings: Mfr=3, Product=2, SerialNumber=...
usb usb6: Product: UHCI Host Controller
usb usb6: Manufacturer: Linux 2.6.32-431.11.2.res6.x86_64 uhci_hcd
usb usb6: SerialNumber: ...
usb usb6: configuration #1 chosen from 1 choice
hub 6-0:1.0: USB hub found
hub 6-0:1.0: 2 ports detected
uhci_hcd 0000:00:1d.1: PCI INT B -> GSI 19 (level, low) -> IRQ 19
uhci_hcd 0000:00:1d.1: setting latency timer to 64
uhci_hcd 0000:00:1d.1: UHCI Host Controller
uhci_hcd 0000:00:1d.1: new USB bus registered, assigned bus number 7
uhci_hcd 0000:00:1d.1: irq 19, io base 0x0000b400
usb usb7: New USB device found, idVendor=1d6b, idProduct=0001
usb usb7: New USB device strings: Mfr=3, Product=2, SerialNumber=...
usb usb7: Product: UHCI Host Controller
usb usb7: Manufacturer: Linux 2.6.32-431.11.2.res6.x86_64 uhci_hcd
usb usb7: SerialNumber: ...
usb usb7: configuration #1 chosen from 1 choice
hub 7-0:1.0: USB hub found
hub 7-0:1.0: 2 ports detected
uhci_hcd 0000:00:1d.2: PCI INT C -> GSI 18 (level, low) -> IRQ 18
uhci_hcd 0000:00:1d.2: setting latency timer to 64
uhci_hcd 0000:00:1d.2: UHCI Host Controller
uhci_hcd 0000:00:1d.2: new USB bus registered, assigned bus number 8
uhci_hcd 0000:00:1d.2: irq 18, io base 0x0000b080
usb usb8: New USB device found, idVendor=1d6b, idProduct=0001
usb usb8: New USB device strings: Mfr=3, Product=2, SerialNumber=...
usb usb8: Product: UHCI Host Controller
usb usb8: Manufacturer: Linux 2.6.32-431.11.2.res6.x86_64 uhci_hcd
usb usb8: SerialNumber: ...
usb usb8: configuration #1 chosen from 1 choice
hub 8-0:1.0: USB hub found
hub 8-0:1.0: 2 ports detected
PNP: No PS/2 controller found. Probing ports directly.
serio: i8042 KBD port at 0x60,0x64 irq 1
serio: i8042 AUX port at 0x60,0x64 irq 12
mice: PS/2 mouse device common for all mice
rtc_cmos 00:03: RTC can wake from S4
rtc_cmos 00:03: rtc core: registered rtc_cmos as rtc0
rtc0: alarms up to one month, y3k, 114 bytes nvram, hpet irqs
cpuidle: using governor ladder
cpuidle: using governor menu
EFI Variables Facility v0.08 2004-May-17
usbcore: registered new interface driver hiddev
usbcore: registered new interface driver usbhid
usbhid: v2.6:USB HID core driver
GRE over IPv4 demultiplexor driver
TCP cubic registered
Initializing XFRM netlink socket
NET: Registered protocol family 17
registered taskstats version 1
rtc_cmos 00:03: setting system clock to 2014-04-18 12:56:18 UTC (1397825778)
Initalizing network drop monitor service
Freeing unused kernel memory: 1280k freed
Write protecting the kernel read-only data: 10240k
Freeing unused kernel memory: 800k freed
Freeing unused kernel memory: 1584k freed
dracut: dracut-004-336.res6
dracut: rd_NO_LUKS: removing cryptoluks activation
device-mapper: uevent: version 1.0.3
device-mapper: ioctl: 4.24.6-ioctl (2013-01-15) initialised: XXX@XXX
udev: starting version 147
dracut: Starting plymouth daemon
ahci 0000:00:1f.2: version 3.0
ahci 0000:00:1f.2: PCI INT B -> GSI 19 (level, low) -> IRQ 19
  alloc irq_desc for 51 on node 0
  alloc kstat_irqs on node 0
ahci 0000:00:1f.2: irq 51 for MSI/MSI-X
ahci: SSS flag set, parallel bus scan disabled
ahci 0000:00:1f.2: AHCI 0001.0200 32 slots 6 ports 3 Gbps 0x3f impl SATA mode
ahci 0000:00:1f.2: flags: 64bit ncq sntf stag pm led clo pio slum part ccc ems sxs 
ahci 0000:00:1f.2: setting latency timer to 64
scsi0 : ahci
scsi1 : ahci
scsi2 : ahci
scsi3 : ahci
scsi4 : ahci
scsi5 : ahci
ata1: SATA max UDMA/133 abar m2048@0xfbed2000 port 0xfbed2100 irq 51
ata2: SATA max UDMA/133 abar m2048@0xfbed2000 port 0xfbed2180 irq 51
ata3: SATA max UDMA/133 abar m2048@0xfbed2000 port 0xfbed2200 irq 51
ata4: SATA max UDMA/133 abar m2048@0xfbed2000 port 0xfbed2280 irq 51
ata5: SATA max UDMA/133 abar m2048@0xfbed2000 port 0xfbed2300 irq 51
ata6: SATA max UDMA/133 abar m2048@0xfbed2000 port 0xfbed2380 irq 51
Refined TSC clocksource calibration: 2400.084 MHz.
Switching to clocksource tsc
ata1: SATA link down (SStatus 0 SControl 300)
usb 4-1: new full speed USB device number 2 using uhci_hcd
usb 4-1: New USB device found, idVendor=0557, idProduct=2221
usb 4-1: New USB device strings: Mfr=1, Product=2, SerialNumber=...
usb 4-1: Product: Hermon USB hidmouse Device
usb 4-1: Manufacturer: Winbond Electronics Corp
usb 4-1: configuration #1 chosen from 1 choice
input: Winbond Electronics Corp Hermon USB hidmouse Device as /devices/pci0000:00/0000:00:1a.1/usb4/4-1/4-1:1.0/input/input3
generic-usb 0003:0557:2221.0001: input,hidraw0: USB HID v1.00 Mouse [Winbond Electronics Corp Hermon USB hidmouse Device] on usb-0000:00:1a.1-1/input0
input: Winbond Electronics Corp Hermon USB hidmouse Device as /devices/pci0000:00/0000:00:1a.1/usb4/4-1/4-1:1.1/input/input4
generic-usb 0003:0557:2221.0002: input,hidraw1: USB HID v1.00 Keyboard [Winbond Electronics Corp Hermon USB hidmouse Device] on usb-0000:00:1a.1-1/input1
ata2: SATA link down (SStatus 0 SControl 300)
ata3: SATA link down (SStatus 0 SControl 300)
ata4: SATA link down (SStatus 0 SControl 300)
ata5: SATA link down (SStatus 0 SControl 300)
ata6: SATA link down (SStatus 0 SControl 300)
megasas: XXX.XXX.XXX.XXX-rh1 Sat. Aug. 31 17:00:00 PDT 2013
megasas: 0x1000:0x0079:0x1000:0x9263: bus 4:slot 0:func 0
  alloc irq_desc for 32 on node 0
  alloc kstat_irqs on node 0
megaraid_sas 0000:04:00.0: PCI INT A -> GSI 32 (level, low) -> IRQ 32
megaraid_sas 0000:04:00.0: setting latency timer to 64
megasas: FW now in Ready state
  alloc irq_desc for 52 on node 0
  alloc kstat_irqs on node 0
megaraid_sas 0000:04:00.0: irq 52 for MSI/MSI-X
megaraid_sas 0000:04:00.0: [scsi6]: FW supports<0> MSIX vector,Online CPUs: <24>,Current MSIX <1>
megasas_init_mfi: fw_support_ieee=0
megasas: INIT adapter done
megaraid_sas 0000:04:00.0: Controller type: MR,Memory size is: 512MB
scsi6 : LSI SAS based MegaRAID driver
scsi 6:0:54:0: Enclosure         LSI CORP SAS2X28          0717 PQ: 0 ANSI: 5
scsi 6:0:57:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:84:0: Enclosure         LSI CORP SAS2X36          0717 PQ: 0 ANSI: 5
scsi 6:0:96:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:97:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:100:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:101:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:102:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:103:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:104:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:105:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:106:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:107:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:108:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:109:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:110:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:111:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:112:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:115:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:116:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:0:120:0: Direct-Access     ATA      Hitachi HUA72302 A580 PQ: 0 ANSI: 5
scsi 6:2:0:0: Direct-Access     LSI      MR9261-8i        2.12 PQ: 0 ANSI: 5
scsi 6:2:1:0: Direct-Access     LSI      MR9261-8i        2.12 PQ: 0 ANSI: 5
sd 6:2:0:0: [sda] 3904294912 512-byte logical blocks: (1.99 TB/1.81 TiB)
sd 6:2:1:0: [sdb] 58564423680 512-byte logical blocks: (29.9 TB/27.2 TiB)
sd 6:2:0:0: [sda] Write Protect is off
sd 6:2:0:0: [sda] Mode Sense: 1f 00 00 08
sd 6:2:1:0: [sdb] Write Protect is off
sd 6:2:1:0: [sdb] Mode Sense: 1f 00 00 08
sd 6:2:1:0: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
sd 6:2:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
 sdb:
 sda: sda1 sda2
sd 6:2:0:0: [sda] Attached SCSI disk
 sdb1
sd 6:2:1:0: [sdb] Attached SCSI disk
dracut: Scanning devices sda2  for LVM logical volumes vg_rosabuildclients004/lv_swap vg_rosabuildclients004/lv_root 
dracut: inactive '/dev/vg_rosabuildclients004/lv_root' [50.00 GiB] inherit
dracut: inactive '/dev/vg_rosabuildclients004/lv_home' [1.67 TiB] inherit
dracut: inactive '/dev/vg_rosabuildclients004/lv_swap' [96.61 GiB] inherit
EXT4-fs (dm-0): mounted filesystem with ordered data mode. Opts: 
dracut: Mounted root filesystem /dev/mapper/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
SELinux:  Disabled at runtime.
SELinux:  Unregistering netfilter hooks
type=1404 audit(1397825782.292:2): selinux=0 auid=4294967295 ses=4294967295
dracut: 
dracut: Switching root
udev: starting version 147
shpchp: Standard Hot Plug PCI Controller Driver version: 0.4
EDAC MC: Ver: 2.1.0 Mar 26 2014
dca service started, version 1.12.1
ioatdma: Intel(R) QuickData Technology Driver 4.00
  alloc irq_desc for 43 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.0: PCI INT A -> GSI 43 (level, low) -> IRQ 43
ioatdma 0000:00:16.0: setting latency timer to 64
  alloc irq_desc for 53 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.0: irq 53 for MSI/MSI-X
  alloc irq_desc for 44 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.1: PCI INT B -> GSI 44 (level, low) -> IRQ 44
ioatdma 0000:00:16.1: setting latency timer to 64
  alloc irq_desc for 54 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.1: irq 54 for MSI/MSI-X
  alloc irq_desc for 45 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.2: PCI INT C -> GSI 45 (level, low) -> IRQ 45
ioatdma 0000:00:16.2: setting latency timer to 64
  alloc irq_desc for 55 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.2: irq 55 for MSI/MSI-X
  alloc irq_desc for 46 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.3: PCI INT D -> GSI 46 (level, low) -> IRQ 46
ioatdma 0000:00:16.3: setting latency timer to 64
  alloc irq_desc for 56 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.3: irq 56 for MSI/MSI-X
ioatdma 0000:00:16.4: PCI INT A -> GSI 43 (level, low) -> IRQ 43
ioatdma 0000:00:16.4: setting latency timer to 64
  alloc irq_desc for 57 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.4: irq 57 for MSI/MSI-X
ioatdma 0000:00:16.5: PCI INT B -> GSI 44 (level, low) -> IRQ 44
ioatdma 0000:00:16.5: setting latency timer to 64
  alloc irq_desc for 58 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.5: irq 58 for MSI/MSI-X
ioatdma 0000:00:16.6: PCI INT C -> GSI 45 (level, low) -> IRQ 45
ioatdma 0000:00:16.6: setting latency timer to 64
  alloc irq_desc for 59 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.6: irq 59 for MSI/MSI-X
ioatdma 0000:00:16.7: PCI INT D -> GSI 46 (level, low) -> IRQ 46
ioatdma 0000:00:16.7: setting latency timer to 64
  alloc irq_desc for 60 on node 0
  alloc kstat_irqs on node 0
ioatdma 0000:00:16.7: irq 60 for MSI/MSI-X
  alloc irq_desc for 22 on node 0
  alloc kstat_irqs on node 0
snd_hda_intel 0000:00:1b.0: PCI INT A -> GSI 22 (level, low) -> IRQ 22
  alloc irq_desc for 61 on node 0
  alloc kstat_irqs on node 0
snd_hda_intel 0000:00:1b.0: irq 61 for MSI/MSI-X
snd_hda_intel 0000:00:1b.0: setting latency timer to 64
hda-intel 0000:00:1b.0: no codecs found!
snd_hda_intel 0000:00:1b.0: PCI INT A disabled
pps_core: LinuxPPS API ver. 1 registered
pps_core: Software ver. 5.3.6 - Copyright FAF7-631D Rodolfo Giometti <XXX@XXX>
PTP clock support registered
e1000e: Intel(R) PRO/1000 Network Driver - 2.3.2-k
e1000e: Copyright(c) 1999 - 2013 Intel Corporation.
e1000e 0000:06:00.0: PCI INT A -> GSI 16 (level, low) -> IRQ 16
e1000e 0000:06:00.0: setting latency timer to 64
e1000e 0000:06:00.0: Interrupt Throttling Rate (ints/sec) set to dynamic conservative mode
e1000e 0000:06:00.0: irq 61 for MSI/MSI-X
  alloc irq_desc for 62 on node 0
  alloc kstat_irqs on node 0
e1000e 0000:06:00.0: irq 62 for MSI/MSI-X
  alloc irq_desc for 63 on node 0
  alloc kstat_irqs on node 0
e1000e 0000:06:00.0: irq 63 for MSI/MSI-X
e1000e 0000:06:00.0: eth0: registered PHC clock
e1000e 0000:06:00.0: eth0: (PCI Express:2.5GT/s:Width x1) XXX
e1000e 0000:06:00.0: eth0: Intel(R) PRO/1000 Network Connection
e1000e 0000:06:00.0: eth0: MAC: 3, PHY: 8, PBA No: 0101FF-0FF
e1000e 0000:07:00.0: PCI INT A -> GSI 17 (level, low) -> IRQ 17
e1000e 0000:07:00.0: setting latency timer to 64
e1000e 0000:07:00.0: Interrupt Throttling Rate (ints/sec) set to dynamic conservative mode
  alloc irq_desc for 64 on node 0
  alloc kstat_irqs on node 0
e1000e 0000:07:00.0: irq 64 for MSI/MSI-X
  alloc irq_desc for 65 on node 0
  alloc kstat_irqs on node 0
e1000e 0000:07:00.0: irq 65 for MSI/MSI-X
  alloc irq_desc for 66 on node 0
  alloc kstat_irqs on node 0
e1000e 0000:07:00.0: irq 66 for MSI/MSI-X
e1000e 0000:07:00.0: eth1: registered PHC clock
e1000e 0000:07:00.0: eth1: (PCI Express:2.5GT/s:Width x1) XXX
e1000e 0000:07:00.0: eth1: Intel(R) PRO/1000 Network Connection
e1000e 0000:07:00.0: eth1: MAC: 3, PHY: 8, PBA No: 0101FF-0FF
ACPI: resource (null) [io  0x0828-0x082f] conflicts with ACPI region PMRG [io 0x800-0x84f]
ACPI: If an ACPI driver is available for this device, you should use it instead of the native driver
lpc_ich: Resource conflict(s) found affecting gpio_ich
i801_smbus 0000:00:1f.3: PCI INT C -> GSI 18 (level, low) -> IRQ 18
ses 6:0:54:0: Attached Enclosure device
ses 6:0:84:0: Attached Enclosure device
ses 6:0:54:0: Attached scsi generic sg0 type 13
ses 6:0:84:0: Attached scsi generic sg1 type 13
sd 6:2:0:0: Attached scsi generic sg2 type 0
sd 6:2:1:0: Attached scsi generic sg3 type 0
iTCO_vendor_support: vendor-support=0
iTCO_wdt: Intel TCO WatchDog Timer Driver v1.07rh
iTCO_wdt: Found a ICH10R TCO device (Version=2, TCOBASE=0x0860)
iTCO_wdt: initialized. heartbeat=30 sec (nowayout=0)
kvm: VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL does not work properly. Using workaround
tun: Universal TUN/TAP device driver, 1.6
tun: (C) 5991-BBB7 Max Krasnyansky <XXX@XXX>
EXT4-fs (sda1): mounted filesystem with ordered data mode. Opts: 
EXT4-fs (dm-2): mounted filesystem with ordered data mode. Opts: 
SGI XFS with ACLs, security attributes, large block/inode numbers, no debug enabled
SGI XFS Quota Management subsystem
XFS (sdb1): Mounting Filesystem
XFS (sdb1): Ending clean mount
fuse init (API version 7.13)
Adding 101302264k swap on /dev/mapper/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  Priority:-1 extents:1 across:101302264k 
NET: Registered protocol family 10
lo: Disabled Privacy Extensions
802.1Q VLAN Support v1.8 Ben Greear <XXX@XXX>
All bugs added by David S. Miller <XXX@XXX>
Ethernet Channel Bonding Driver: v3.6.0 (September 26, 2009)
bonding: bond0: setting mode to 802.3ad (4).
bonding: bond0: Setting MII monitoring interval to 100.
bonding: bond0: Setting LACP rate to fast (1).
bonding: bond0: setting xmit hash policy to layer2 (0).
bonding: bond0: setting mode to 802.3ad (4).
bonding: bond0: Setting MII monitoring interval to 100.
bonding: bond0: Setting LACP rate to fast (1).
bonding: bond0: setting xmit hash policy to layer2 (0).
ADDRCONF(NETDEV_UP): bond0: link is not ready
8021q: adding VLAN 0 to HW filter on device bond0
bonding: bond0: setting mode to 802.3ad (4).
bonding: bond0: Setting MII monitoring interval to 100.
bonding: bond0: Setting LACP rate to fast (1).
bonding: bond0: setting xmit hash policy to layer2 (0).
bonding: bond0: Adding slave eth0.
8021q: adding VLAN 0 to HW filter on device eth0
bonding: bond0: enslaving eth0 as a backup interface with a down link.
bonding: bond0: Adding slave eth1.
8021q: adding VLAN 0 to HW filter on device eth1
bonding: bond0: enslaving eth1 as a backup interface with a down link.
Bridge firewalling registered
ADDRCONF(NETDEV_UP): bond0: link is not ready
8021q: adding VLAN 0 to HW filter on device bond0
device bond0 entered promiscuous mode
device eth0 entered promiscuous mode
device eth1 entered promiscuous mode
8021q: adding VLAN 0 to HW filter on device br0
e1000e: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: None
bond0: link status definitely up for interface eth0, 1000 Mbps full duplex.
ADDRCONF(NETDEV_CHANGE): bond0: link becomes ready
br0: port 1(bond0) entering forwarding state
e1000e: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: None
bond0: link status definitely up for interface eth1, 1000 Mbps full duplex.
br0: no IPv6 routers present
bond0: no IPv6 routers present
br0: port 1(bond0) entering forwarding state
RPC: Registered named UNIX socket transport module.
RPC: Registered udp transport module.
RPC: Registered tcp transport module.
RPC: Registered tcp NFSv4.1 backchannel transport module.
Slow work thread pool: Starting up
Slow work thread pool: Ready
FS-Cache: Loaded
NFS: Registering the id_resolver key type
FS-Cache: Netfs 'nfs' registered for caching
device virbr0-nic entered promiscuous mode
virbr0: starting userspace STP failed, starting kernel STP
ip_tables: (C) FCB9-52CA Netfilter Core Team
nf_conntrack version 0.5.0 (16384 buckets, 65536 max)
8021q: adding VLAN 0 to HW filter on device virbr0
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffff8109b310>] ? wake_bit_function+0x0/0x50
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff810a1277>] ? down_trylock+0x37/0x50
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff81136923>] ? __lru_cache_add+0x73/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff81136923>] ? __lru_cache_add+0x73/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c9610>] ? do_mpage_readpage+0x150/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffffa032d0c5>] ? kmem_free+0x35/0x40 [xfs]
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff8114239e>] ? __inc_zone_page_state+0x2e/0x30
 [<ffffffff811368f0>] ? __lru_cache_add+0x40/0x90
 [<ffffffff811c9c09>] ? mpage_readpages+0xe9/0x130
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffffa032e84d>] ? xfs_vm_readpages+0x1d/0x20 [xfs]
 [<ffffffff81135585>] ? __do_page_cache_readahead+0x185/0x210
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff81135bc3>] ? page_cache_sync_readahead+0x33/0x50
 [<ffffffff81121658>] ? generic_file_aio_read+0x558/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 2674, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff8111fa37>] ? unlock_page+0x27/0x30
 [<ffffffff811c0c13>] ? block_read_full_page+0x2b3/0x3a0
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffff81167aaa>] ? alloc_pages_current+0xaa/0x110
 [<ffffffff8113558e>] ? __do_page_cache_readahead+0x18e/0x210
 [<ffffffff811c9aff>] ? mpage_readpage+0x4f/0x70
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff81135631>] ? ra_submit+0x21/0x30
 [<ffffffff811359a5>] ? ondemand_readahead+0x115/0x240
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffffa032e8e8>] ? xfs_vm_readpage+0x18/0x20 [xfs]
 [<ffffffff811212fc>] ? generic_file_aio_read+0x1fc/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
Ebtables v2.0 registered
ip6_tables: (C) FCB9-52CA Netfilter Core Team
lo: Disabled Privacy Extensions
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
vnet0: no IPv6 routers present
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
XFS (sdb1): corrupt dinode 146, (btree extents).
ffff880c1d350000: 42 4d 41 50 00 00 00 da 00 00 00 00 10 62 f8 4b  BMAP.........b.K
XFS (sdb1): Internal error xfs_bmap_read_extents(1) at line 4166 of file fs/xfs/xfs_bmap.c.  Caller 0xffffffffa0311896

Pid: 3700, comm: libvirtd Not tainted 2.6.32-431.11.2.res6.x86_64 #1
Call Trace:
 [<ffffffffa0307e5f>] ? xfs_error_report+0x3f/0x50 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0307ece>] ? xfs_corruption_error+0x5e/0x90 [xfs]
 [<ffffffffa02e92b4>] ? xfs_bmap_read_extents+0x334/0x350 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa0311896>] ? xfs_iread_extents+0x86/0x110 [xfs]
 [<ffffffffa02f0b8e>] ? xfs_bmapi+0x1be/0xee0 [xfs]
 [<ffffffff8100988e>] ? __switch_to+0x26e/0x320
 [<ffffffff81061059>] ? find_busiest_queue+0x69/0x150
 [<ffffffff81529be6>] ? down_write+0x16/0x40
 [<ffffffffa032ddae>] ? __xfs_get_blocks+0x12e/0x500 [xfs]
 [<ffffffff81149bb3>] ? do_wp_page+0x493/0x920
 [<ffffffffa032e1b1>] ? xfs_get_blocks+0x11/0x20 [xfs]
 [<ffffffff811c0afb>] ? block_read_full_page+0x19b/0x3a0
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffffa03306e5>] ? xfs_buf_cond_lock+0x25/0x80 [xfs]
 [<ffffffff811c988f>] ? do_mpage_readpage+0x3cf/0x5f0
 [<ffffffffa0331c34>] ? xfs_buf_get+0x34/0x1b0 [xfs]
 [<ffffffffa0330ff5>] ? xfs_buf_rele+0x55/0x100 [xfs]
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff811c9aff>] ? mpage_readpage+0x4f/0x70
 [<ffffffffa032e1a0>] ? xfs_get_blocks+0x0/0x20 [xfs]
 [<ffffffff811989ff>] ? do_lookup+0x9f/0x230
 [<ffffffff811a3c6a>] ? dput+0x9a/0x150
 [<ffffffff811976d5>] ? path_to_nameidata+0x25/0x60
 [<ffffffffa02e2f7c>] ? xfs_attr_get_int+0x3c/0x120 [xfs]
 [<ffffffffa032e8e8>] ? xfs_vm_readpage+0x18/0x20 [xfs]
 [<ffffffff811212fc>] ? generic_file_aio_read+0x1fc/0x700
 [<ffffffffa033404c>] ? xfs_file_aio_read+0x16c/0x2c0 [xfs]
 [<ffffffff81188e8a>] ? do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] ? vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] ? sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] ? system_call_fastpath+0x16/0x1b
XFS (sdb1): Corruption detected. Unmount and run xfs_repair
lo: Disabled Privacy Extensions
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
kvm: 4685: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
vnet0: no IPv6 routers present
br0: port 2(vnet0) entering forwarding state
device vnet1 entered promiscuous mode
br0: port 3(vnet1) entering forwarding state
vnet1: no IPv6 routers present
kvm: 4823: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
br0: port 3(vnet1) entering forwarding state
INFO: task xfssyncd/sdb1:1415 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
xfssyncd/sdb1 D 0000000000000006     0  1415      2 0x00000000
 ffff880c2bf19a20 0000000000000046 0000000000000000 0000000000000000
 ffff88182af64e80 ffff880c2ab805e0 ffffffff81380230 ffff880c2ab80f54
 ffff880c2c013ab8 ffff880c2bf19fd8 000000000000fbc8 ffff880c2c013ab8
Call Trace:
 [<ffffffff81380230>] ? scsi_done+0x0/0x60
 [<ffffffff815286c3>] io_schedule+0x73/0xc0
 [<ffffffff81267c98>] get_request_wait+0x108/0x1d0
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff81267df9>] blk_queue_bio+0x99/0x620
 [<ffffffff81266e80>] generic_make_request+0x240/0x5a0
 [<ffffffff81267250>] submit_bio+0x70/0x120
 [<ffffffffa03303ba>] _xfs_buf_ioapply+0x16a/0x200 [xfs]
 [<ffffffffa0316eba>] ? xlog_bdstrat+0x2a/0x60 [xfs]
 [<ffffffffa033207f>] xfs_buf_iorequest+0x4f/0xe0 [xfs]
 [<ffffffffa0316eba>] xlog_bdstrat+0x2a/0x60 [xfs]
 [<ffffffffa0318699>] xlog_sync+0x269/0x3e0 [xfs]
 [<ffffffffa03188c3>] xlog_state_release_iclog+0xb3/0xf0 [xfs]
 [<ffffffffa0318d52>] _xfs_log_force+0x122/0x240 [xfs]
 [<ffffffffa0319038>] xfs_log_force+0x38/0x90 [xfs]
 [<ffffffffa033c142>] xfs_sync_worker+0x52/0xa0 [xfs]
 [<ffffffffa033c05e>] xfssyncd+0x17e/0x210 [xfs]
 [<ffffffffa033bee0>] ? xfssyncd+0x0/0x210 [xfs]
 [<ffffffff8109aee6>] kthread+0x96/0xa0
 [<ffffffff8100c20a>] child_rip+0xa/0x20
 [<ffffffff8109ae50>] ? kthread+0x0/0xa0
 [<ffffffff8100c200>] ? child_rip+0x0/0x20
INFO: task qemu-kvm:13083 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
qemu-kvm      D 0000000000000000     0 13083      1 0x00000080
 ffff88104ed01cc8 0000000000000086 0000000000000000 000000000000000b
 ffff880c2a8a0138 ffff880c2a8a0048 ffff880c29a92078 ffff880c29a92078
 ffff88117c913af8 ffff88104ed01fd8 000000000000fbc8 ffff88117c913af8
Call Trace:
 [<ffffffff8111f920>] ? sync_page+0x0/0x50
 [<ffffffff815286c3>] io_schedule+0x73/0xc0
 [<ffffffff8111f95d>] sync_page+0x3d/0x50
 [<ffffffff8152918f>] __wait_on_bit+0x5f/0x90
 [<ffffffff8111fb93>] wait_on_page_bit+0x73/0x80
 [<ffffffff8109b310>] ? wake_bit_function+0x0/0x50
 [<ffffffff81135c05>] ? pagevec_lookup_tag+0x25/0x40
 [<ffffffff8111ffbb>] wait_on_page_writeback_range+0xfb/0x190
 [<ffffffff81120188>] filemap_write_and_wait_range+0x78/0x90
 [<ffffffff811bab0e>] vfs_fsync_range+0x7e/0x100
 [<ffffffff811babfd>] vfs_fsync+0x1d/0x20
 [<ffffffff811bac3e>] do_fsync+0x3e/0x60
 [<ffffffff811bac73>] sys_fdatasync+0x13/0x20
 [<ffffffff8100b072>] system_call_fastpath+0x16/0x1b
sd 6:2:0:0: [sda] megasas: RESET -3540353 cmd=2a retries=0
megasas: [ 0]waiting for 145 commands to complete
megasas: [ 5]waiting for 145 commands to complete
megasas: [10]waiting for 145 commands to complete
megasas: [15]waiting for 145 commands to complete
megasas: [20]waiting for 145 commands to complete
megasas: [25]waiting for 145 commands to complete
megasas: [30]waiting for 145 commands to complete
megasas: [35]waiting for 145 commands to complete
megasas: [40]waiting for 145 commands to complete
megasas: [45]waiting for 145 commands to complete
megasas: [50]waiting for 145 commands to complete
megasas: [55]waiting for 145 commands to complete
megasas: [60]waiting for 145 commands to complete
megasas: [65]waiting for 145 commands to complete
megasas: [70]waiting for 145 commands to complete
INFO: task jbd2/dm-0-8:719 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
jbd2/dm-0-8   D 0000000000000013     0   719      2 0x00000000
 ffff880c29099d20 0000000000000046 0000000000016840 0000000000016840
 ffff88182d530800 0000000000016840 0000000000016840 ffff880c298d7500
 ffff880c298d7ab8 ffff880c29099fd8 000000000000fbc8 ffff880c298d7ab8
Call Trace:
 [<ffffffff8109b5be>] ? prepare_to_wait+0x4e/0x80
 [<ffffffffa007280f>] jbd2_journal_commit_transaction+0x19f/0x1500 [jbd2]
 [<ffffffff810096f0>] ? __switch_to+0xd0/0x320
 [<ffffffff8108410c>] ? lock_timer_base+0x3c/0x70
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffffa0078a48>] kjournald2+0xb8/0x220 [jbd2]
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffffa0078990>] ? kjournald2+0x0/0x220 [jbd2]
 [<ffffffff8109aee6>] kthread+0x96/0xa0
 [<ffffffff8100c20a>] child_rip+0xa/0x20
 [<ffffffff8109ae50>] ? kthread+0x0/0xa0
 [<ffffffff8100c200>] ? child_rip+0x0/0x20
INFO: task xfssyncd/sdb1:1415 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
xfssyncd/sdb1 D 0000000000000006     0  1415      2 0x00000000
 ffff880c2bf19a20 0000000000000046 0000000000000000 0000000000000000
 ffff88182af64e80 ffff880c2ab805e0 ffffffff81380230 ffff880c2ab80f54
 ffff880c2c013ab8 ffff880c2bf19fd8 000000000000fbc8 ffff880c2c013ab8
Call Trace:
 [<ffffffff81380230>] ? scsi_done+0x0/0x60
 [<ffffffff815286c3>] io_schedule+0x73/0xc0
 [<ffffffff81267c98>] get_request_wait+0x108/0x1d0
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff81267df9>] blk_queue_bio+0x99/0x620
 [<ffffffff81266e80>] generic_make_request+0x240/0x5a0
 [<ffffffff81267250>] submit_bio+0x70/0x120
 [<ffffffffa03303ba>] _xfs_buf_ioapply+0x16a/0x200 [xfs]
 [<ffffffffa0316eba>] ? xlog_bdstrat+0x2a/0x60 [xfs]
 [<ffffffffa033207f>] xfs_buf_iorequest+0x4f/0xe0 [xfs]
 [<ffffffffa0316eba>] xlog_bdstrat+0x2a/0x60 [xfs]
 [<ffffffffa0318699>] xlog_sync+0x269/0x3e0 [xfs]
 [<ffffffffa03188c3>] xlog_state_release_iclog+0xb3/0xf0 [xfs]
 [<ffffffffa0318d52>] _xfs_log_force+0x122/0x240 [xfs]
 [<ffffffffa0319038>] xfs_log_force+0x38/0x90 [xfs]
 [<ffffffffa033c142>] xfs_sync_worker+0x52/0xa0 [xfs]
 [<ffffffffa033c05e>] xfssyncd+0x17e/0x210 [xfs]
 [<ffffffffa033bee0>] ? xfssyncd+0x0/0x210 [xfs]
 [<ffffffff8109aee6>] kthread+0x96/0xa0
 [<ffffffff8100c20a>] child_rip+0xa/0x20
 [<ffffffff8109ae50>] ? kthread+0x0/0xa0
 [<ffffffff8100c200>] ? child_rip+0x0/0x20
INFO: task master:2503 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
master        D 0000000000000013     0  2503      1 0x00000080
 ffff88182ae3b948 0000000000000086 0000000000000000 ffffffffa000443c
 00000037ffffffc8 0000004100000000 ffff880c4002ac68 0000000000000001
 ffff88182a3165f8 ffff88182ae3bfd8 000000000000fbc8 ffff88182a3165f8
Call Trace:
 [<ffffffffa000443c>] ? dm_table_unplug_all+0x5c/0x100 [dm_mod]
 [<ffffffff811bf1f0>] ? sync_buffer+0x0/0x50
 [<ffffffff815286c3>] io_schedule+0x73/0xc0
 [<ffffffff811bf230>] sync_buffer+0x40/0x50
 [<ffffffff81528f5a>] __wait_on_bit_lock+0x5a/0xc0
 [<ffffffff811bf1f0>] ? sync_buffer+0x0/0x50
 [<ffffffff81529038>] out_of_line_wait_on_bit_lock+0x78/0x90
 [<ffffffff8109b310>] ? wake_bit_function+0x0/0x50
 [<ffffffff811be789>] ? __find_get_block+0xa9/0x200
 [<ffffffff811bf3d6>] __lock_buffer+0x36/0x40
 [<ffffffffa0072293>] do_get_write_access+0x493/0x520 [jbd2]
 [<ffffffffa0072471>] jbd2_journal_get_write_access+0x31/0x50 [jbd2]
 [<ffffffffa00bfd98>] __ext4_journal_get_write_access+0x38/0x80 [ext4]
 [<ffffffffa0099bd3>] ext4_reserve_inode_write+0x73/0xa0 [ext4]
 [<ffffffffa0099c4c>] ext4_mark_inode_dirty+0x4c/0x1d0 [ext4]
 [<ffffffffa0071495>] ? jbd2_journal_start+0xb5/0x100 [jbd2]
 [<ffffffffa0099f40>] ext4_dirty_inode+0x40/0x60 [ext4]
 [<ffffffff811b49cb>] __mark_inode_dirty+0x3b/0x160
 [<ffffffff811a50d2>] file_update_time+0xf2/0x170
 [<ffffffff81193dc2>] pipe_write+0x302/0x6a0
 [<ffffffff81188d4a>] do_sync_write+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff8118e884>] ? cp_new_stat+0xe4/0x100
 [<ffffffff810149b9>] ? read_tsc+0x9/0x20
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189048>] vfs_write+0xb8/0x1a0
 [<ffffffff81189941>] sys_write+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] system_call_fastpath+0x16/0x1b
INFO: task qemu-kvm:13083 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
qemu-kvm      D 0000000000000000     0 13083      1 0x00000080
 ffff88104ed01cc8 0000000000000086 0000000000000000 000000000000000b
 ffff880c2a8a0138 ffff880c2a8a0048 ffff880c29a92078 ffff880c29a92078
 ffff88117c913af8 ffff88104ed01fd8 000000000000fbc8 ffff88117c913af8
Call Trace:
 [<ffffffff8111f920>] ? sync_page+0x0/0x50
 [<ffffffff815286c3>] io_schedule+0x73/0xc0
 [<ffffffff8111f95d>] sync_page+0x3d/0x50
 [<ffffffff8152918f>] __wait_on_bit+0x5f/0x90
 [<ffffffff8111fb93>] wait_on_page_bit+0x73/0x80
 [<ffffffff8109b310>] ? wake_bit_function+0x0/0x50
 [<ffffffff81135c05>] ? pagevec_lookup_tag+0x25/0x40
 [<ffffffff8111ffbb>] wait_on_page_writeback_range+0xfb/0x190
 [<ffffffff81120188>] filemap_write_and_wait_range+0x78/0x90
 [<ffffffff811bab0e>] vfs_fsync_range+0x7e/0x100
 [<ffffffff811babfd>] vfs_fsync+0x1d/0x20
 [<ffffffff811bac3e>] do_fsync+0x3e/0x60
 [<ffffffff811bac73>] sys_fdatasync+0x13/0x20
 [<ffffffff8100b072>] system_call_fastpath+0x16/0x1b
INFO: task pickup:12312 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
pickup        D 0000000000000012     0 12312   2503 0x00000080
 ffff880fc57d1968 0000000000000082 0000000000000000 ffffffffa000443c
 ffff880fc57d1a08 ffffffff8112f3a3 ffff880c40010dc0 ffffffff00000000
 ffff88182ab20638 ffff880fc57d1fd8 000000000000fbc8 ffff88182ab20638
Call Trace:
 [<ffffffffa000443c>] ? dm_table_unplug_all+0x5c/0x100 [dm_mod]
 [<ffffffff8112f3a3>] ? __alloc_pages_nodemask+0x113/0x8d0
 [<ffffffff811bf1f0>] ? sync_buffer+0x0/0x50
 [<ffffffff815286c3>] io_schedule+0x73/0xc0
 [<ffffffff811bf230>] sync_buffer+0x40/0x50
 [<ffffffff81528f5a>] __wait_on_bit_lock+0x5a/0xc0
 [<ffffffff8116e4ea>] ? kmem_getpages+0xba/0x170
 [<ffffffff811bf1f0>] ? sync_buffer+0x0/0x50
 [<ffffffff81529038>] out_of_line_wait_on_bit_lock+0x78/0x90
 [<ffffffff8109b310>] ? wake_bit_function+0x0/0x50
 [<ffffffff811be789>] ? __find_get_block+0xa9/0x200
 [<ffffffff811bf3d6>] __lock_buffer+0x36/0x40
 [<ffffffffa0072293>] do_get_write_access+0x493/0x520 [jbd2]
 [<ffffffffa0072471>] jbd2_journal_get_write_access+0x31/0x50 [jbd2]
 [<ffffffffa00bfd98>] __ext4_journal_get_write_access+0x38/0x80 [ext4]
 [<ffffffffa0099bd3>] ext4_reserve_inode_write+0x73/0xa0 [ext4]
 [<ffffffffa0099c4c>] ext4_mark_inode_dirty+0x4c/0x1d0 [ext4]
 [<ffffffffa0071495>] ? jbd2_journal_start+0xb5/0x100 [jbd2]
 [<ffffffffa0099f40>] ext4_dirty_inode+0x40/0x60 [ext4]
 [<ffffffff811b49cb>] __mark_inode_dirty+0x3b/0x160
 [<ffffffff811a52e5>] touch_atime+0x195/0x1a0
 [<ffffffff81194435>] pipe_read+0x2d5/0x4e0
 [<ffffffff81188e8a>] do_sync_read+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189775>] vfs_read+0xb5/0x1a0
 [<ffffffff811898b1>] sys_read+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] system_call_fastpath+0x16/0x1b
megasas: [75]waiting for 145 commands to complete
megasas: [80]waiting for 145 commands to complete
megasas: [85]waiting for 145 commands to complete
megasas: [90]waiting for 145 commands to complete
megasas: [95]waiting for 145 commands to complete
megasas: [100]waiting for 145 commands to complete
megasas: [105]waiting for 145 commands to complete
megasas: [110]waiting for 145 commands to complete
megasas: [115]waiting for 145 commands to complete
megasas: [120]waiting for 145 commands to complete
megasas: [125]waiting for 145 commands to complete
megasas: [130]waiting for 145 commands to complete
megasas: [135]waiting for 145 commands to complete
megasas: [140]waiting for 145 commands to complete
megasas: [145]waiting for 145 commands to complete
megasas: [150]waiting for 145 commands to complete
megasas: [155]waiting for 145 commands to complete
megasas: [160]waiting for 145 commands to complete
megasas: [165]waiting for 145 commands to complete
megasas: [170]waiting for 145 commands to complete
megasas: [175]waiting for 145 commands to complete
megasas: moving cmd[0]:ffff880c2ab61a40:0:ffff88020deca4c0 the defer queue as internal
megasas: moving cmd[1]:ffff880c2abd12c0:0:ffff880c2aa085c0 the defer queue as internal
megasas: moving cmd[2]:ffff880c2af75dc0:0:ffff8807b3e55980 the defer queue as internal
megasas: moving cmd[3]:ffff880c2ab3d2c0:0:ffff880c12294780 the defer queue as internal
megasas: moving cmd[4]:ffff880c2ab3cdc0:0:ffff8809118b7e80 the defer queue as internal
megasas: moving cmd[5]:ffff880c2ab3c840:0:ffff880c2ab983c0 the defer queue as internal
megasas: moving cmd[6]:ffff880c2ab3c740:0:ffff880c2aa8b5c0 the defer queue as internal
megasas: moving cmd[7]:ffff880c2ab3c540:0:ffff8807b3e55780 the defer queue as internal
megasas: moving cmd[8]:ffff880c2ab39e40:0:ffff880c2aa8bbc0 the defer queue as internal
megasas: moving cmd[9]:ffff880c2ab396c0:0:ffff880c2aa8b7c0 the defer queue as internal
megasas: moving cmd[10]:ffff880c2ab395c0:0:ffff880c2ab985c0 the defer queue as internal
megasas: moving cmd[11]:ffff880c2ab392c0:0:ffff88020deca5c0 the defer queue as internal
megasas: moving cmd[12]:ffff880c2ab39240:0:ffff880c2ab82980 the defer queue as internal
megasas: moving cmd[13]:ffff880c2ab38bc0:0:ffff88020deca1c0 the defer queue as internal
megasas: moving cmd[14]:ffff880c2ab38940:0:ffff8808624932c0 the defer queue as internal
megasas: moving cmd[15]:ffff880c2ab388c0:0:ffff8808624931c0 the defer queue as internal
megasas: moving cmd[16]:ffff880c2ab38740:0:ffff880c29975480 the defer queue as internal
megasas: moving cmd[17]:ffff880c2ab35d40:0:ffff880c2aa8b8c0 the defer queue as internal
megasas: moving cmd[18]:ffff880c2ab351c0:0:ffff8803313441c0 the defer queue as internal
megasas: moving cmd[19]:ffff880c2aa8dc40:0:ffff880911b7dc80 the defer queue as internal
megasas: moving cmd[20]:ffff880c2aa8d9c0:0:ffff880139dfcd80 the defer queue as internal
megasas: moving cmd[21]:ffff880c2aa8d940:0:ffff8809118b7280 the defer queue as internal
megasas: moving cmd[22]:ffff880c2aa8d4c0:0:ffff88020decaec0 the defer queue as internal
megasas: moving cmd[23]:ffff880c2aa8d240:0:ffff8808624937c0 the defer queue as internal
megasas: moving cmd[24]:ffff880c2aa8d0c0:0:ffff880911b7db80 the defer queue as internal
megasas: moving cmd[25]:ffff880c2a9381c0:0:ffff880c12294380 the defer queue as internal
megasas: moving cmd[26]:ffff880c2abd1cc0:0:ffff880c2aa087c0 the defer queue as internal
megasas: moving cmd[27]:ffff880c2abd1b40:0:ffff8803313446c0 the defer queue as internal
megasas: moving cmd[28]:ffff880c2abd16c0:0:ffff880c2ab82d80 the defer queue as internal
megasas: moving cmd[29]:ffff880c2abd1640:0:ffff880139dfce80 the defer queue as internal
megasas: moving cmd[30]:ffff880c2aadbac0:0:ffff880c12294a80 the defer queue as internal
megasas: moving cmd[31]:ffff880c2aadb1c0:0:ffff880c12294d80 the defer queue as internal
megasas: moving cmd[32]:ffff880c29acdf40:0:ffff88020deca6c0 the defer queue as internal
megasas: moving cmd[33]:ffff880c29acde40:0:ffff8809118b7680 the defer queue as internal
megasas: moving cmd[34]:ffff880c29acdbc0:0:ffff880c29975280 the defer queue as internal
megasas: moving cmd[35]:ffff880c29acd640:0:ffff8809118b7c80 the defer queue as internal
megasas: moving cmd[36]:ffff880c29acd5c0:0:ffff8808624935c0 the defer queue as internal
megasas: moving cmd[37]:ffff880c29acd240:0:ffff8807b3e55880 the defer queue as internal
megasas: moving cmd[38]:ffff880c29accdc0:0:ffff880139dfc280 the defer queue as internal
megasas: moving cmd[39]:ffff880c29acc340:0:ffff880c2aa8b3c0 the defer queue as internal
megasas: moving cmd[40]:ffff880c29acbe40:0:ffff880872923ec0 the defer queue as internal
megasas: moving cmd[41]:ffff880c29acbc40:0:ffff880c2ab98ec0 the defer queue as internal
megasas: moving cmd[42]:ffff880c29acb2c0:0:ffff8808729233c0 the defer queue as internal
megasas: moving cmd[43]:ffff880c29acb140:0:ffff880331344bc0 the defer queue as internal
megasas: moving cmd[44]:ffff880c29aacf40:0:ffff8808729239c0 the defer queue as internal
megasas: moving cmd[45]:ffff880c29aace40:0:ffff880c2ab82180 the defer queue as internal
megasas: moving cmd[46]:ffff880c29aacac0:0:ffff880b695a7c80 the defer queue as internal
megasas: moving cmd[47]:ffff880c29aac940:0:ffff880c2aa08ec0 the defer queue as internal
megasas: moving cmd[48]:ffff880c29aac7c0:0:ffff880c2ab82e80 the defer queue as internal
megasas: moving cmd[49]:ffff880c29aac740:0:ffff8809118b7080 the defer queue as internal
megasas: moving cmd[50]:ffff880c29aac2c0:0:ffff880c2ab82880 the defer queue as internal
megasas: moving cmd[51]:ffff880c29aac0c0:0:ffff880911b7d780 the defer queue as internal
megasas: moving cmd[52]:ffff880c29aadec0:0:ffff880139dfc980 the defer queue as internal
megasas: moving cmd[53]:ffff880c29aadb40:0:ffff880c2ab82480 the defer queue as internal
megasas: moving cmd[54]:ffff880c29aad6c0:0:ffff88020decaac0 the defer queue as internal
megasas: moving cmd[55]:ffff880c29aad3c0:0:ffff880c29975780 the defer queue as internal
megasas: moving cmd[56]:ffff880c29aaeac0:0:ffff880c2ab987c0 the defer queue as internal
megasas: moving cmd[57]:ffff880c29aae840:0:ffff880c12294b80 the defer queue as internal
megasas: moving cmd[58]:ffff880c29aae2c0:0:ffff8808624930c0 the defer queue as internal
megasas: moving cmd[59]:ffff880c29aae240:0:ffff880c12294280 the defer queue as internal
megasas: moving cmd[60]:ffff880c29aafdc0:0:ffff880911b7d680 the defer queue as internal
megasas: moving cmd[61]:ffff880c29aafc40:0:ffff880c2ab82c80 the defer queue as internal
megasas: moving cmd[62]:ffff880c29aafac0:0:ffff8808624933c0 the defer queue as internal
megasas: moving cmd[63]:ffff880c29aaf9c0:0:ffff880911b7d080 the defer queue as internal
megasas: moving cmd[64]:ffff880c29aaf940:0:ffff880b695a7980 the defer queue as internal
megasas: moving cmd[65]:ffff880c29aaf6c0:0:ffff8808729230c0 the defer queue as internal
megasas: moving cmd[66]:ffff880c29aaf3c0:0:ffff880911b7d580 the defer queue as internal
megasas: moving cmd[67]:ffff880c29aaf2c0:0:ffff880139dfc180 the defer queue as internal
megasas: moving cmd[68]:ffff880c29ab0f40:0:ffff880c12294480 the defer queue as internal
megasas: moving cmd[69]:ffff880c29ab0dc0:0:ffff88020decacc0 the defer queue as internal
megasas: moving cmd[70]:ffff880c29ab09c0:0:ffff880862493cc0 the defer queue as internal
megasas: moving cmd[71]:ffff880c29ab0840:0:ffff880c2ab988c0 the defer queue as internal
megasas: moving cmd[72]:ffff880c29ab06c0:0:ffff880c2ab986c0 the defer queue as internal
megasas: moving cmd[73]:ffff880c29ab00c0:0:ffff880911b7d980 the defer queue as internal
megasas: moving cmd[74]:ffff880c29ab1cc0:0:ffff880b695a7080 the defer queue as internal
megasas: moving cmd[75]:ffff880c29ab1bc0:0:ffff880872923dc0 the defer queue as internal
megasas: moving cmd[76]:ffff880c29ab1940:0:ffff8808624934c0 the defer queue as internal
megasas: moving cmd[77]:ffff880c29ab1740:0:ffff8808624938c0 the defer queue as internal
megasas: moving cmd[78]:ffff880c29ab1440:0:ffff880862493dc0 the defer queue as internal
megasas: moving cmd[79]:ffff880c29ab2f40:0:ffff8809118b7a80 the defer queue as internal
megasas: moving cmd[80]:ffff880c29ab2e40:0:ffff8808729232c0 the defer queue as internal
megasas: moving cmd[81]:ffff880c29ab2c40:0:ffff880872923cc0 the defer queue as internal
megasas: moving cmd[82]:ffff880c29ab2ac0:0:ffff8808729231c0 the defer queue as internal
megasas: moving cmd[83]:ffff880c29ab2a40:0:ffff880c2ab98bc0 the defer queue as internal
megasas: moving cmd[84]:ffff880c29ab2640:0:ffff880c12294880 the defer queue as internal
megasas: moving cmd[85]:ffff880c29ab25c0:0:ffff88020decadc0 the defer queue as internal
megasas: moving cmd[86]:ffff880c29ab2540:0:ffff880139dfc880 the defer queue as internal
megasas: moving cmd[87]:ffff880c29ab2240:0:ffff880911b7d480 the defer queue as internal
megasas: moving cmd[88]:ffff880c29ab2140:0:ffff880c2ab981c0 the defer queue as internal
megasas: moving cmd[89]:ffff880c29ab3440:0:ffff880b695a7380 the defer queue as internal
megasas: moving cmd[90]:ffff880c29ab32c0:0:ffff880c2aa8bac0 the defer queue as internal
megasas: moving cmd[91]:ffff880c29ab4ec0:0:ffff880c29975180 the defer queue as internal
megasas: moving cmd[92]:ffff880c29ab4e40:0:ffff8809118b7480 the defer queue as internal
megasas: moving cmd[93]:ffff880c29ab46c0:0:ffff880331344ac0 the defer queue as internal
megasas: moving cmd[94]:ffff880c29ab45c0:0:ffff880c2aa083c0 the defer queue as internal
megasas: moving cmd[95]:ffff880c29ab40c0:0:ffff8807b3e55480 the defer queue as internal
megasas: moving cmd[96]:ffff880c29ab5ec0:0:ffff880c2aa8b6c0 the defer queue as internal
megasas: moving cmd[97]:ffff880c29ab5ac0:0:ffff880c12294e80 the defer queue as internal
megasas: moving cmd[98]:ffff880c29ab6940:0:ffff880c2ab82b80 the defer queue as internal
megasas: moving cmd[99]:ffff880c29ab60c0:0:ffff880c2ab98cc0 the defer queue as internal
megasas: moving cmd[100]:ffff880c29ab78c0:0:ffff880c2aa08bc0 the defer queue as internal
megasas: moving cmd[101]:ffff880c29ab7640:0:ffff880c2aa08ac0 the defer queue as internal
megasas: moving cmd[102]:ffff880c29ab7540:0:ffff880911b7d380 the defer queue as internal
megasas: moving cmd[103]:ffff880c29ab7440:0:ffff880911b7da80 the defer queue as internal
megasas: moving cmd[104]:ffff880c29ab70c0:0:ffff880911b7d280 the defer queue as internal
megasas: moving cmd[105]:ffff880c29ab8d40:0:ffff8809118b7880 the defer queue as internal
megasas: moving cmd[106]:ffff880c29ab8cc0:0:ffff880c2ab980c0 the defer queue as internal
megasas: moving cmd[107]:ffff880c29ab8c40:0:ffff880911b7dd80 the defer queue as internal
megasas: moving cmd[108]:ffff880c29ab8840:0:ffff880c29975680 the defer queue as internal
megasas: moving cmd[109]:ffff880c29ab8740:0:ffff880139dfc480 the defer queue as internal
megasas: moving cmd[110]:ffff880c29ab9f40:0:ffff8807b3e55280 the defer queue as internal
megasas: moving cmd[111]:ffff880c29ab9cc0:0:ffff880fc56cd4c0 the defer queue as internal
megasas: moving cmd[112]:ffff880c29ab9640:0:ffff880c12294080 the defer queue as internal
megasas: moving cmd[113]:ffff880c29abadc0:0:ffff880c2aa08cc0 the defer queue as internal
megasas: moving cmd[114]:ffff880c29abacc0:0:ffff880c2aa084c0 the defer queue as internal
megasas: moving cmd[115]:ffff880c29abac40:0:ffff8808624939c0 the defer queue as internal
megasas: moving cmd[116]:ffff880c29abaa40:0:ffff880862493ec0 the defer queue as internal
megasas: moving cmd[117]:ffff880c29abbec0:0:ffff8807b3e55180 the defer queue as internal
megasas: moving cmd[118]:ffff880c29abbcc0:0:ffff880c2ab82680 the defer queue as internal
megasas: moving cmd[119]:ffff880c29abbc40:0:ffff880c2aa088c0 the defer queue as internal
megasas: moving cmd[120]:ffff880c29abb540:0:ffff880c2ab82780 the defer queue as internal
megasas: moving cmd[121]:ffff880c29abb340:0:ffff880139dfc780 the defer queue as internal
megasas: moving cmd[122]:ffff880c29abccc0:0:ffff880c29975580 the defer queue as internal
megasas: moving cmd[123]:ffff880c29abca40:0:ffff8807b3e55c80 the defer queue as internal
megasas: moving cmd[124]:ffff880c29abc9c0:0:ffff880b695a7880 the defer queue as internal
megasas: moving cmd[125]:ffff880c29abc6c0:0:ffff880c2aa8b9c0 the defer queue as internal
megasas: moving cmd[126]:ffff880c29abc540:0:ffff8807b3e55d80 the defer queue as internal
megasas: moving cmd[127]:ffff880c29abc4c0:0:ffff880c2ab98ac0 the defer queue as internal
megasas: moving cmd[128]:ffff880c29abc3c0:0:ffff8808729235c0 the defer queue as internal
megasas: moving cmd[129]:ffff880c29abdb40:0:ffff880c12294580 the defer queue as internal
megasas: moving cmd[130]:ffff880c29abd840:0:ffff8809118b7380 the defer queue as internal
megasas: moving cmd[131]:ffff880c29abd540:0:ffff880862493ac0 the defer queue as internal
megasas: moving cmd[132]:ffff880c29abd2c0:0:ffff880b695a7680 the defer queue as internal
megasas: moving cmd[133]:ffff880c29ad3b40:0:ffff880b695a7280 the defer queue as internal
megasas: moving cmd[134]:ffff880c29ad4bc0:0:ffff8803313449c0 the defer queue as internal
megasas: moving cmd[135]:ffff880c29ad4940:0:ffff880c2aa8b0c0 the defer queue as internal
megasas: moving cmd[136]:ffff880c29ad5ec0:0:ffff880c2ab82080 the defer queue as internal
megasas: moving cmd[137]:ffff880c29ad58c0:0:ffff8803313448c0 the defer queue as internal
megasas: moving cmd[138]:ffff880c29ad5640:0:ffff8809118b7b80 the defer queue as internal
megasas: moving cmd[139]:ffff880c29ad5440:0:ffff88020deca0c0 the defer queue as internal
megasas: moving cmd[140]:ffff880c29ad51c0:0:ffff8809118b7780 the defer queue as internal
megasas: moving cmd[141]:ffff880c29ad5140:0:ffff880c2ab82a80 the defer queue as internal
megasas: moving cmd[142]:ffff880c29ad50c0:0:ffff8807b3e55380 the defer queue as internal
megasas: moving cmd[143]:ffff880c29ad6440:0:ffff8809118b7580 the defer queue as internal
megasas: moving cmd[144]:ffff880c29ad7f40:0:ffff880c2aa8bdc0 the defer queue as internal
megaraid_sas: FW detected to be in faultstate, restarting it...
ADP_RESET_GEN2: HostDiag=a0
megaraid_sas: FW restarted successfully,initiating next stage...
megaraid_sas: HBA recovery state machine,state 2 starting...
INFO: task jbd2/dm-0-8:719 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
jbd2/dm-0-8   D 0000000000000013     0   719      2 0x00000000
 ffff880c29099d20 0000000000000046 0000000000016840 0000000000016840
 ffff88182d530800 0000000000016840 0000000000016840 ffff880c298d7500
 ffff880c298d7ab8 ffff880c29099fd8 000000000000fbc8 ffff880c298d7ab8
Call Trace:
 [<ffffffff8109b5be>] ? prepare_to_wait+0x4e/0x80
 [<ffffffffa007280f>] jbd2_journal_commit_transaction+0x19f/0x1500 [jbd2]
 [<ffffffff810096f0>] ? __switch_to+0xd0/0x320
 [<ffffffff8108410c>] ? lock_timer_base+0x3c/0x70
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffffa0078a48>] kjournald2+0xb8/0x220 [jbd2]
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffffa0078990>] ? kjournald2+0x0/0x220 [jbd2]
 [<ffffffff8109aee6>] kthread+0x96/0xa0
 [<ffffffff8100c20a>] child_rip+0xa/0x20
 [<ffffffff8109ae50>] ? kthread+0x0/0xa0
 [<ffffffff8100c200>] ? child_rip+0x0/0x20
INFO: task xfssyncd/sdb1:1415 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
xfssyncd/sdb1 D 0000000000000006     0  1415      2 0x00000000
 ffff880c2bf19a20 0000000000000046 0000000000000000 0000000000000000
 ffff88182af64e80 ffff880c2ab805e0 ffffffff81380230 ffff880c2ab80f54
 ffff880c2c013ab8 ffff880c2bf19fd8 000000000000fbc8 ffff880c2c013ab8
Call Trace:
 [<ffffffff81380230>] ? scsi_done+0x0/0x60
 [<ffffffff815286c3>] io_schedule+0x73/0xc0
 [<ffffffff81267c98>] get_request_wait+0x108/0x1d0
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff81267df9>] blk_queue_bio+0x99/0x620
 [<ffffffff81266e80>] generic_make_request+0x240/0x5a0
 [<ffffffff81267250>] submit_bio+0x70/0x120
 [<ffffffffa03303ba>] _xfs_buf_ioapply+0x16a/0x200 [xfs]
 [<ffffffffa0316eba>] ? xlog_bdstrat+0x2a/0x60 [xfs]
 [<ffffffffa033207f>] xfs_buf_iorequest+0x4f/0xe0 [xfs]
 [<ffffffffa0316eba>] xlog_bdstrat+0x2a/0x60 [xfs]
 [<ffffffffa0318699>] xlog_sync+0x269/0x3e0 [xfs]
 [<ffffffffa03188c3>] xlog_state_release_iclog+0xb3/0xf0 [xfs]
 [<ffffffffa0318d52>] _xfs_log_force+0x122/0x240 [xfs]
 [<ffffffffa0319038>] xfs_log_force+0x38/0x90 [xfs]
 [<ffffffffa033c142>] xfs_sync_worker+0x52/0xa0 [xfs]
 [<ffffffffa033c05e>] xfssyncd+0x17e/0x210 [xfs]
 [<ffffffffa033bee0>] ? xfssyncd+0x0/0x210 [xfs]
 [<ffffffff8109aee6>] kthread+0x96/0xa0
 [<ffffffff8100c20a>] child_rip+0xa/0x20
 [<ffffffff8109ae50>] ? kthread+0x0/0xa0
 [<ffffffff8100c200>] ? child_rip+0x0/0x20
INFO: task rs:main Q:Reg:1876 blocked for more than 120 seconds.
      Not tainted 2.6.32-431.11.2.res6.x86_64 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
rs:main Q:Reg D 0000000000000012     0  1876      1 0x00000080
 ffff880c2bfdba88 0000000000000086 0000000000000000 ffff880c28052ca8
 ffff881051ff03d8 0000000000000000 ffff880c2bfdba28 0000000300000001
 ffff880c29029ab8 ffff880c2bfdbfd8 000000000000fbc8 ffff880c29029ab8
Call Trace:
 [<ffffffffa007108a>] start_this_handle+0x25a/0x480 [jbd2]
 [<ffffffff8116ecab>] ? cache_alloc_refill+0x15b/0x240
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffffa0071495>] jbd2_journal_start+0xb5/0x100 [jbd2]
 [<ffffffffa00b0eb6>] ext4_journal_start_sb+0x56/0xe0 [ext4]
 [<ffffffffa0099f2a>] ext4_dirty_inode+0x2a/0x60 [ext4]
 [<ffffffff811b49cb>] __mark_inode_dirty+0x3b/0x160
 [<ffffffff811a50d2>] file_update_time+0xf2/0x170
 [<ffffffff81121cf0>] __generic_file_aio_write+0x230/0x490
 [<ffffffff81121fd8>] generic_file_aio_write+0x88/0x100
 [<ffffffffa0093fd8>] ext4_file_write+0x58/0x190 [ext4]
 [<ffffffff81188d4a>] do_sync_write+0xfa/0x140
 [<ffffffff8109b290>] ? autoremove_wake_function+0x0/0x40
 [<ffffffff81059b21>] ? update_curr+0xe1/0x1f0
 [<ffffffff81226496>] ? security_file_permission+0x16/0x20
 [<ffffffff81189048>] vfs_write+0xb8/0x1a0
 [<ffffffff81189941>] sys_write+0x51/0x90
 [<ffffffff810e1e4e>] ? __audit_syscall_exit+0x25e/0x290
 [<ffffffff8100b072>] system_call_fastpath+0x16/0x1b
megasas: Waiting for FW to come to ready state
megasas: FW now in Ready state
megaraid_sas: command ffff880c2ab61a40, ffff88020deca4c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab61a40 scsi cmd [8a],0x360551detected on the internal queue, issue again.
megaraid_sas: command ffff880c2abd12c0, ffff880c2aa085c0:0detected to be pending while HBA reset.
megasas: ffff880c2abd12c0 scsi cmd [8a],0x3604fcdetected on the internal queue, issue again.
megaraid_sas: command ffff880c2af75dc0, ffff8807b3e55980:0detected to be pending while HBA reset.
megasas: ffff880c2af75dc0 scsi cmd [8a],0x360538detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab3d2c0, ffff880c12294780:0detected to be pending while HBA reset.
megasas: ffff880c2ab3d2c0 scsi cmd [8a],0x360510detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab3cdc0, ffff8809118b7e80:0detected to be pending while HBA reset.
megasas: ffff880c2ab3cdc0 scsi cmd [8a],0x360537detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab3c840, ffff880c2ab983c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab3c840 scsi cmd [8a],0x360565detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab3c740, ffff880c2aa8b5c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab3c740 scsi cmd [8a],0x360509detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab3c540, ffff8807b3e55780:0detected to be pending while HBA reset.
megasas: ffff880c2ab3c540 scsi cmd [8a],0x36050cdetected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab39e40, ffff880c2aa8bbc0:0detected to be pending while HBA reset.
megasas: ffff880c2ab39e40 scsi cmd [8a],0x3604bbdetected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab396c0, ffff880c2aa8b7c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab396c0 scsi cmd [8a],0x3604b7detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab395c0, ffff880c2ab985c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab395c0 scsi cmd [8a],0x3604d8detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab392c0, ffff88020deca5c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab392c0 scsi cmd [8a],0x360561detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab39240, ffff880c2ab82980:0detected to be pending while HBA reset.
megasas: ffff880c2ab39240 scsi cmd [8a],0x36056edetected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab38bc0, ffff88020deca1c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab38bc0 scsi cmd [8a],0x36049edetected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab38940, ffff8808624932c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab38940 scsi cmd [8a],0x3604cbdetected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab388c0, ffff8808624931c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab388c0 scsi cmd [8a],0x3604d3detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab38740, ffff880c29975480:0detected to be pending while HBA reset.
megasas: ffff880c2ab38740 scsi cmd [8a],0x3604cadetected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab35d40, ffff880c2aa8b8c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab35d40 scsi cmd [8a],0x3604b8detected on the internal queue, issue again.
megaraid_sas: command ffff880c2ab351c0, ffff8803313441c0:0detected to be pending while HBA reset.
megasas: ffff880c2ab351c0 scsi cmd [8a],0x3604c2detected on the internal queue, issue again.
megaraid_sas: command ffff880c2aa8dc40, ffff880911b7dc80:0detected to be pending while HBA reset.
megasas: ffff880c2aa8dc40 scsi cmd [8a],0x3604acdetected on the internal queue, issue again.
megaraid_sas: command ffff880c2aa8d9c0, ffff880139dfcd80:0detected to be pending while HBA reset.
megasas: ffff880c2aa8d9c0 scsi cmd [8a],0x3604b5detected on the internal queue, issue again.
megaraid_sas: command ffff880c2aa8d940, ffff8809118b7280:0detected to be pending while HBA reset.
megasas: ffff880c2aa8d940 scsi cmd [8a],0x3604f3detected on the internal queue, issue again.
megaraid_sas: command ffff880c2aa8d4c0, ffff88020decaec0:0detected to be pending while HBA reset.
megasas: ffff880c2aa8d4c0 scsi cmd [8a],0x3604a2detected on the internal queue, issue again.
megaraid_sas: command ffff880c2aa8d240, ffff8808624937c0:0detected to be pending while HBA reset.
megasas: ffff880c2aa8d240 scsi cmd [8a],0x3604d1detected on the internal queue, issue again.
megaraid_sas: command ffff880c2aa8d0c0, ffff880911b7db80:0detected to be pending while HBA reset.
megasas: ffff880c2aa8d0c0 scsi cmd [8a],0x36056ddetected on the internal queue, issue again.
megaraid_sas: command ffff880c2a9381c0, ffff880c12294380:0detected to be pending while HBA reset.
megasas: ffff880c2a9381c0 scsi cmd [8a],0x36054edetected on the internal queue, issue again.
megaraid_sas: command ffff880c2abd1cc0, ffff880c2aa087c0:0detected to be pending while HBA reset.
megasas: ffff880c2abd1cc0 scsi cmd [8a],0x36050bdetected on the internal queue, issue again.
megaraid_sas: command ffff880c2abd1b40, ffff8803313446c0:0detected to be pending while HBA reset.
megasas: ffff880c2abd1b40 scsi cmd [8a],0x3604c3detected on the internal queue, issue again.
megaraid_sas: command ffff880c2abd16c0, ffff880c2ab82d80:0detected to be pending while HBA reset.
megasas: ffff880c2abd16c0 scsi cmd [8a],0x360539detected on the internal queue, issue again.
megaraid_sas: command ffff880c2abd1640, ffff880139dfce80:0detected to be pending while HBA reset.
megasas: ffff880c2abd1640 scsi cmd [8a],0x3604b2detected on the internal queue, issue again.
megaraid_sas: command ffff880c2aadbac0, ffff880c12294a80:0detected to be pending while HBA reset.
megasas: ffff880c2aadbac0 scsi cmd [8a],0x36054fdetected on the internal queue, issue again.
megaraid_sas: command ffff880c2aadb1c0, ffff880c12294d80:0detected to be pending while HBA reset.
megasas: ffff880c2aadb1c0 scsi cmd [8a],0x360549detected on the internal queue, issue again.
megaraid_sas: command ffff880c29acdf40, ffff88020deca6c0:0detected to be pending while HBA reset.
megasas: ffff880c29acdf40 scsi cmd [8a],0x36057cdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29acde40, ffff8809118b7680:0detected to be pending while HBA reset.
megasas: ffff880c29acde40 scsi cmd [8a],0x360575detected on the internal queue, issue again.
megaraid_sas: command ffff880c29acdbc0, ffff880c29975280:0detected to be pending while HBA reset.
megasas: ffff880c29acdbc0 scsi cmd [8a],0x3604c7detected on the internal queue, issue again.
megaraid_sas: command ffff880c29acd640, ffff8809118b7c80:0detected to be pending while HBA reset.
megasas: ffff880c29acd640 scsi cmd [8a],0x3604f7detected on the internal queue, issue again.
megaraid_sas: command ffff880c29acd5c0, ffff8808624935c0:0detected to be pending while HBA reset.
megasas: ffff880c29acd5c0 scsi cmd [8a],0x3604ccdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29acd240, ffff8807b3e55880:0detected to be pending while HBA reset.
megasas: ffff880c29acd240 scsi cmd [8a],0x360558detected on the internal queue, issue again.
megaraid_sas: command ffff880c29accdc0, ffff880139dfc280:0detected to be pending while HBA reset.
megasas: ffff880c29accdc0 scsi cmd [8a],0x3604b0detected on the internal queue, issue again.
megaraid_sas: command ffff880c29acc340, ffff880c2aa8b3c0:0detected to be pending while HBA reset.
megasas: ffff880c29acc340 scsi cmd [8a],0x360552detected on the internal queue, issue again.
megaraid_sas: command ffff880c29acbe40, ffff880872923ec0:0detected to be pending while HBA reset.
megasas: ffff880c29acbe40 scsi cmd [8a],0x36056fdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29acbc40, ffff880c2ab98ec0:0detected to be pending while HBA reset.
megasas: ffff880c29acbc40 scsi cmd [8a],0x360564detected on the internal queue, issue again.
megaraid_sas: command ffff880c29acb2c0, ffff8808729233c0:0detected to be pending while HBA reset.
megasas: ffff880c29acb2c0 scsi cmd [8a],0x36050fdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29acb140, ffff880331344bc0:0detected to be pending while HBA reset.
megasas: ffff880c29acb140 scsi cmd [8a],0x3604c1detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aacf40, ffff8808729239c0:0detected to be pending while HBA reset.
megasas: ffff880c29aacf40 scsi cmd [8a],0x36054bdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aace40, ffff880c2ab82180:0detected to be pending while HBA reset.
megasas: ffff880c29aace40 scsi cmd [8a],0x360562detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aacac0, ffff880b695a7c80:0detected to be pending while HBA reset.
megasas: ffff880c29aacac0 scsi cmd [8a],0x36056bdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aac940, ffff880c2aa08ec0:0detected to be pending while HBA reset.
megasas: ffff880c29aac940 scsi cmd [8a],0x3604fbdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aac7c0, ffff880c2ab82e80:0detected to be pending while HBA reset.
megasas: ffff880c29aac7c0 scsi cmd [8a],0x36050edetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aac740, ffff8809118b7080:0detected to be pending while HBA reset.
megasas: ffff880c29aac740 scsi cmd [8a],0x360571detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aac2c0, ffff880c2ab82880:0detected to be pending while HBA reset.
megasas: ffff880c29aac2c0 scsi cmd [8a],0x360573detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aac0c0, ffff880911b7d780:0detected to be pending while HBA reset.
megasas: ffff880c29aac0c0 scsi cmd [8a],0x3604abdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aadec0, ffff880139dfc980:0detected to be pending while HBA reset.
megasas: ffff880c29aadec0 scsi cmd [8a],0x3604b6detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aadb40, ffff880c2ab82480:0detected to be pending while HBA reset.
megasas: ffff880c29aadb40 scsi cmd [8a],0x36054cdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aad6c0, ffff88020decaac0:0detected to be pending while HBA reset.
megasas: ffff880c29aad6c0 scsi cmd [8a],0x3604a1detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aad3c0, ffff880c29975780:0detected to be pending while HBA reset.
megasas: ffff880c29aad3c0 scsi cmd [8a],0x3604c6detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aaeac0, ffff880c2ab987c0:0detected to be pending while HBA reset.
megasas: ffff880c29aaeac0 scsi cmd [8a],0x3604dadetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aae840, ffff880c12294b80:0detected to be pending while HBA reset.
megasas: ffff880c29aae840 scsi cmd [8a],0x36057bdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aae2c0, ffff8808624930c0:0detected to be pending while HBA reset.
megasas: ffff880c29aae2c0 scsi cmd [8a],0x3604d4detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aae240, ffff880c12294280:0detected to be pending while HBA reset.
megasas: ffff880c29aae240 scsi cmd [8a],0x36057ddetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aafdc0, ffff880911b7d680:0detected to be pending while HBA reset.
megasas: ffff880c29aafdc0 scsi cmd [8a],0x3604a7detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aafc40, ffff880c2ab82c80:0detected to be pending while HBA reset.
megasas: ffff880c29aafc40 scsi cmd [8a],0x360550detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aafac0, ffff8808624933c0:0detected to be pending while HBA reset.
megasas: ffff880c29aafac0 scsi cmd [8a],0x3604d7detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aaf9c0, ffff880911b7d080:0detected to be pending while HBA reset.
megasas: ffff880c29aaf9c0 scsi cmd [8a],0x3604a8detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aaf940, ffff880b695a7980:0detected to be pending while HBA reset.
megasas: ffff880c29aaf940 scsi cmd [8a],0x360535detected on the internal queue, issue again.
megaraid_sas: command ffff880c29aaf6c0, ffff8808729230c0:0detected to be pending while HBA reset.
megasas: ffff880c29aaf6c0 scsi cmd [8a],0x36056cdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aaf3c0, ffff880911b7d580:0detected to be pending while HBA reset.
megasas: ffff880c29aaf3c0 scsi cmd [8a],0x3604aadetected on the internal queue, issue again.
megaraid_sas: command ffff880c29aaf2c0, ffff880139dfc180:0detected to be pending while HBA reset.
megasas: ffff880c29aaf2c0 scsi cmd [8a],0x3604afdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab0f40, ffff880c12294480:0detected to be pending while HBA reset.
megasas: ffff880c29ab0f40 scsi cmd [8a],0x360548detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab0dc0, ffff88020decacc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab0dc0 scsi cmd [8a],0x3604a0detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab09c0, ffff880862493cc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab09c0 scsi cmd [8a],0x3604cedetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab0840, ffff880c2ab988c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab0840 scsi cmd [8a],0x3604dddetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab06c0, ffff880c2ab986c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab06c0 scsi cmd [8a],0x3604dcdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab00c0, ffff880911b7d980:0detected to be pending while HBA reset.
megasas: ffff880c29ab00c0 scsi cmd [8a],0x3604a9detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab1cc0, ffff880b695a7080:0detected to be pending while HBA reset.
megasas: ffff880c29ab1cc0 scsi cmd [8a],0x360578detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab1bc0, ffff880872923dc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab1bc0 scsi cmd [8a],0x360511detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab1940, ffff8808624934c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab1940 scsi cmd [8a],0x3604d5detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab1740, ffff8808624938c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab1740 scsi cmd [8a],0x3604d6detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab1440, ffff880862493dc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab1440 scsi cmd [8a],0x3604cfdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2f40, ffff8809118b7a80:0detected to be pending while HBA reset.
megasas: ffff880c29ab2f40 scsi cmd [8a],0x360568detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2e40, ffff8808729232c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab2e40 scsi cmd [8a],0x360560detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2c40, ffff880872923cc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab2c40 scsi cmd [8a],0x360554detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2ac0, ffff8808729231c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab2ac0 scsi cmd [8a],0x36052cdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2a40, ffff880c2ab98bc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab2a40 scsi cmd [8a],0x3604dbdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2640, ffff880c12294880:0detected to be pending while HBA reset.
megasas: ffff880c29ab2640 scsi cmd [8a],0x360557detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab25c0, ffff88020decadc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab25c0 scsi cmd [8a],0x36049fdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2540, ffff880139dfc880:0detected to be pending while HBA reset.
megasas: ffff880c29ab2540 scsi cmd [8a],0x3604b4detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2240, ffff880911b7d480:0detected to be pending while HBA reset.
megasas: ffff880c29ab2240 scsi cmd [8a],0x3604a6detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab2140, ffff880c2ab981c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab2140 scsi cmd [8a],0x360572detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab3440, ffff880b695a7380:0detected to be pending while HBA reset.
megasas: ffff880c29ab3440 scsi cmd [8a],0x36050adetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab32c0, ffff880c2aa8bac0:0detected to be pending while HBA reset.
megasas: ffff880c29ab32c0 scsi cmd [8a],0x3604bddetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab4ec0, ffff880c29975180:0detected to be pending while HBA reset.
megasas: ffff880c29ab4ec0 scsi cmd [8a],0x3604c5detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab4e40, ffff8809118b7480:0detected to be pending while HBA reset.
megasas: ffff880c29ab4e40 scsi cmd [8a],0x3604f5detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab46c0, ffff880331344ac0:0detected to be pending while HBA reset.
megasas: ffff880c29ab46c0 scsi cmd [8a],0x3604c0detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab45c0, ffff880c2aa083c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab45c0 scsi cmd [8a],0x3604fddetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab40c0, ffff8807b3e55480:0detected to be pending while HBA reset.
megasas: ffff880c29ab40c0 scsi cmd [8a],0x36055fdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab5ec0, ffff880c2aa8b6c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab5ec0 scsi cmd [8a],0x3604badetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab5ac0, ffff880c12294e80:0detected to be pending while HBA reset.
megasas: ffff880c29ab5ac0 scsi cmd [8a],0x36056adetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab6940, ffff880c2ab82b80:0detected to be pending while HBA reset.
megasas: ffff880c29ab6940 scsi cmd [8a],0x360566detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab60c0, ffff880c2ab98cc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab60c0 scsi cmd [8a],0x360553detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab78c0, ffff880c2aa08bc0:0detected to be pending while HBA reset.
megasas: ffff880c29ab78c0 scsi cmd [8a],0x3604fadetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab7640, ffff880c2aa08ac0:0detected to be pending while HBA reset.
megasas: ffff880c29ab7640 scsi cmd [8a],0x3604f8detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab7540, ffff880911b7d380:0detected to be pending while HBA reset.
megasas: ffff880c29ab7540 scsi cmd [8a],0x3604addetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab7440, ffff880911b7da80:0detected to be pending while HBA reset.
megasas: ffff880c29ab7440 scsi cmd [8a],0x3604aedetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab70c0, ffff880911b7d280:0detected to be pending while HBA reset.
megasas: ffff880c29ab70c0 scsi cmd [8a],0x3604a4detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab8d40, ffff8809118b7880:0detected to be pending while HBA reset.
megasas: ffff880c29ab8d40 scsi cmd [8a],0x3604f4detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab8cc0, ffff880c2ab980c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab8cc0 scsi cmd [8a],0x36052edetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab8c40, ffff880911b7dd80:0detected to be pending while HBA reset.
megasas: ffff880c29ab8c40 scsi cmd [8a],0x3604a5detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab8840, ffff880c29975680:0detected to be pending while HBA reset.
megasas: ffff880c29ab8840 scsi cmd [8a],0x3604c9detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab8740, ffff880139dfc480:0detected to be pending while HBA reset.
megasas: ffff880c29ab8740 scsi cmd [8a],0x3604b3detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab9f40, ffff8807b3e55280:0detected to be pending while HBA reset.
megasas: ffff880c29ab9f40 scsi cmd [8a],0x36052fdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab9cc0, ffff880fc56cd4c0:0detected to be pending while HBA reset.
megasas: ffff880c29ab9cc0 scsi cmd [2a],0x360581detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ab9640, ffff880c12294080:0detected to be pending while HBA reset.
megasas: ffff880c29ab9640 scsi cmd [8a],0x36054adetected on the internal queue, issue again.
megaraid_sas: command ffff880c29abadc0, ffff880c2aa08cc0:0detected to be pending while HBA reset.
megasas: ffff880c29abadc0 scsi cmd [8a],0x3604ffdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29abacc0, ffff880c2aa084c0:0detected to be pending while HBA reset.
megasas: ffff880c29abacc0 scsi cmd [8a],0x3604fedetected on the internal queue, issue again.
megaraid_sas: command ffff880c29abac40, ffff8808624939c0:0detected to be pending while HBA reset.
megasas: ffff880c29abac40 scsi cmd [8a],0x3604cddetected on the internal queue, issue again.
megaraid_sas: command ffff880c29abaa40, ffff880862493ec0:0detected to be pending while HBA reset.
megasas: ffff880c29abaa40 scsi cmd [8a],0x3604d2detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abbec0, ffff8807b3e55180:0detected to be pending while HBA reset.
megasas: ffff880c29abbec0 scsi cmd [8a],0x36050ddetected on the internal queue, issue again.
megaraid_sas: command ffff880c29abbcc0, ffff880c2ab82680:0detected to be pending while HBA reset.
megasas: ffff880c29abbcc0 scsi cmd [8a],0x36054ddetected on the internal queue, issue again.
megaraid_sas: command ffff880c29abbc40, ffff880c2aa088c0:0detected to be pending while HBA reset.
megasas: ffff880c29abbc40 scsi cmd [8a],0x3604f9detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abb540, ffff880c2ab82780:0detected to be pending while HBA reset.
megasas: ffff880c29abb540 scsi cmd [8a],0x360500detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abb340, ffff880139dfc780:0detected to be pending while HBA reset.
megasas: ffff880c29abb340 scsi cmd [8a],0x3604b1detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abccc0, ffff880c29975580:0detected to be pending while HBA reset.
megasas: ffff880c29abccc0 scsi cmd [8a],0x3604c8detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abca40, ffff8807b3e55c80:0detected to be pending while HBA reset.
megasas: ffff880c29abca40 scsi cmd [8a],0x360579detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abc9c0, ffff880b695a7880:0detected to be pending while HBA reset.
megasas: ffff880c29abc9c0 scsi cmd [8a],0x360570detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abc6c0, ffff880c2aa8b9c0:0detected to be pending while HBA reset.
megasas: ffff880c29abc6c0 scsi cmd [8a],0x3604bcdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29abc540, ffff8807b3e55d80:0detected to be pending while HBA reset.
megasas: ffff880c29abc540 scsi cmd [8a],0x360577detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abc4c0, ffff880c2ab98ac0:0detected to be pending while HBA reset.
megasas: ffff880c29abc4c0 scsi cmd [8a],0x3604d9detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abc3c0, ffff8808729235c0:0detected to be pending while HBA reset.
megasas: ffff880c29abc3c0 scsi cmd [8a],0x3604dedetected on the internal queue, issue again.
megaraid_sas: command ffff880c29abdb40, ffff880c12294580:0detected to be pending while HBA reset.
megasas: ffff880c29abdb40 scsi cmd [8a],0x360555detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abd840, ffff8809118b7380:0detected to be pending while HBA reset.
megasas: ffff880c29abd840 scsi cmd [8a],0x360569detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abd540, ffff880862493ac0:0detected to be pending while HBA reset.
megasas: ffff880c29abd540 scsi cmd [8a],0x3604d0detected on the internal queue, issue again.
megaraid_sas: command ffff880c29abd2c0, ffff880b695a7680:0detected to be pending while HBA reset.
megasas: ffff880c29abd2c0 scsi cmd [8a],0x360574detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad3b40, ffff880b695a7280:0detected to be pending while HBA reset.
megasas: ffff880c29ad3b40 scsi cmd [8a],0x360563detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad4bc0, ffff8803313449c0:0detected to be pending while HBA reset.
megasas: ffff880c29ad4bc0 scsi cmd [8a],0x3604bfdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad4940, ffff880c2aa8b0c0:0detected to be pending while HBA reset.
megasas: ffff880c29ad4940 scsi cmd [8a],0x3604bedetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad5ec0, ffff880c2ab82080:0detected to be pending while HBA reset.
megasas: ffff880c29ad5ec0 scsi cmd [8a],0x36057adetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad58c0, ffff8803313448c0:0detected to be pending while HBA reset.
megasas: ffff880c29ad58c0 scsi cmd [8a],0x3604c4detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad5640, ffff8809118b7b80:0detected to be pending while HBA reset.
megasas: ffff880c29ad5640 scsi cmd [8a],0x36057edetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad5440, ffff88020deca0c0:0detected to be pending while HBA reset.
megasas: ffff880c29ad5440 scsi cmd [8a],0x3604a3detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad51c0, ffff8809118b7780:0detected to be pending while HBA reset.
megasas: ffff880c29ad51c0 scsi cmd [8a],0x3604f6detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad5140, ffff880c2ab82a80:0detected to be pending while HBA reset.
megasas: ffff880c29ad5140 scsi cmd [8a],0x360576detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad50c0, ffff8807b3e55380:0detected to be pending while HBA reset.
megasas: ffff880c29ad50c0 scsi cmd [2a],0x36057fdetected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad6440, ffff8809118b7580:0detected to be pending while HBA reset.
megasas: ffff880c29ad6440 scsi cmd [8a],0x360567detected on the internal queue, issue again.
megaraid_sas: command ffff880c29ad7f40, ffff880c2aa8bdc0:0detected to be pending while HBA reset.
megasas: ffff880c29ad7f40 scsi cmd [8a],0x3604b9detected on the internal queue, issue again.
megaraid_sas: aen_cmd in def process
megasas: reset successful 
sd 6:2:1:0: [sdb] megasas: RESET -3540126 cmd=8a retries=0
megaraid_sas: no pending cmds after reset
megasas: reset successful 
kvm: 4685: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 4823: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 4685: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 4823: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
br0: port 2(vnet0) entering disabled state
device vnet0 left promiscuous mode
br0: port 2(vnet0) entering disabled state
br0: port 3(vnet1) entering disabled state
device vnet1 left promiscuous mode
br0: port 3(vnet1) entering disabled state
device vnet0 entered promiscuous mode
br0: port 2(vnet0) entering forwarding state
device vnet1 entered promiscuous mode
br0: port 3(vnet1) entering forwarding state
vnet0: no IPv6 routers present
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
br0: port 2(vnet0) entering forwarding state
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
vnet1: no IPv6 routers present
br0: port 3(vnet1) entering forwarding state
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
Clocksource tsc unstable (delta = -8589931259 ns).  Enable clocksource failover by adding clocksource_failover kernel parameter.
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
NOHZ: local_softirq_pending 100
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
hrtimer: interrupt took 9926 ns
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17833: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
kvm: 17980: cpu0 disabled perfctr wrmsr: 0xc1 data 0xffff
lp: driver loaded but no devices found
lp: driver loaded but no devices found
st: Version 20130315rh, fixed bufsize 32768, s/g segs 256
BIOS EDD facility v0.16 2004-Jun-25, 2 devices found
ppdev: user-space parallel port driver
